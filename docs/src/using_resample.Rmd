# Resampled Performance


## Algorithms

Model performance can be estimated with resampling methods that simulate repeated training and test set fits and predictions.  With these methods, performance metrics are computed on each resample to produce an empirical distribution for inference.  Resampling is controlled in the **MachineShop** with the functions:

`r rdoc_url("BootControl()", "MLControl")`
  : Simple bootstrap resampling [@efron:1993:IB].  Models are repeatedly fit with bootstrap resampled training sets and used to predict the full dataset.

`r rdoc_url("BootOptimismControl()", "MLControl")`
  : Optimism-corrected bootstrap resampling [@efron:1983:LLB; @harrell:1996:MPM].

`r rdoc_url("CVControl()", "MLControl")`
  : Repeated K-fold cross-validation [@kohavi:1995:SCB].  The full dataset is repeatedly partitioned into K-folds.  For a given partitioning, prediction is performed on each of the K folds with models fit on all remaining folds.  10-fold cross-validation is the package default.

`r rdoc_url("CVOptimismControl()", "MLControl")`
  :  Optimism-corrected cross-validation [@davison:1997:BMA, eq. 6.48].

`r rdoc_url("OOBControl()", "MLControl")`
  : Out-of-bootstrap resampling.  Models are fit with bootstrap resampled training sets and used to predict the unsampled cases.
  
`r rdoc_url("SplitControl()", "MLControl")`
  : Split training and test sets [@hastie:2009:ESL7].  The data are randomly partitioned into a training and test set.
  
`r rdoc_url("TrainControl()", "MLControl")`
  : Training resubstitution.  A model is fit on and used to predict the full training set in order to estimate training, or apparent, error [@efron:1986:HBA].
  
For the survival example, repeated cross-validation control structures are defined to estimate model performance in predicting survival means and 5 and 10-year survival probabilities.  In addition to arguments controlling the resampling algorithms, a `seed` can be set to ensure reproducibility of resampling results obtained with the structures.

```{r using_resample_control}
## Control parameters for K-fold cross-validation

## Prediction of survival means
surv_means_control <- CVControl(folds = 5, repeats = 3, seed = 123)

## Prediction of survival probabilities
surv_probs_control <- CVControl(folds = 5, repeats = 3, times = surv_times, seed = 123)
```


## Parallel Processing

Resampling is implemented with the **foreach** package [@microsoft:2019:FPF] and will run in parallel if a compatible backend is loaded, such as that provided by the **doParallel** [@microsoft:2019:DFP] or **doSNOW** package [@microsoft:2019:DFS].

```{r using_resample_parallel}
## Register multiple cores for parallel computations
library(doParallel)
registerDoParallel(cores = 2)
```


## Resample Function

Resampling is performed by calling the `r rdoc_url("resample()")` function with a variable specification, model, and control structure.  Like the `r rdoc_url("fit()")` function, variables may be specified in terms of a traditional formula, design matrix, model frame, or recipe.

```{r using_resample_function}
## Resample estimation for survival means and probabilities
(res_means <- resample(surv_fo, data = surv_train, model = GBMModel, control = surv_means_control))

(res_probs <- resample(surv_fo, data = surv_train, model = GBMModel, control = surv_probs_control))
```


## Summary Statistics

The `r rdoc_url("summary()")` function when applied directly to output from `r rdoc_url("resample()")` computes summary statistics for the default performance metrics described in the *Performance Function* section.

```{r using_resample_summary}
## Summary of survival means metric
summary(res_means)

## Summary of survival probability metrics
summary(res_probs)
```

Other relevant metrics can be identified with `r rdoc_url("metricinfo()")` and summarized with `r rdoc_url("performance()")`.

```{r using_resample_summary_performance}
## Resample-specific metrics
metricinfo(res_means) %>% names

## User-specified survival means metrics
summary(performance(res_means, metrics = c(cindex, rmse)))
```

Furthermore, summaries can be customized with a user-defined statistics function or list of statistics functions passed to the `stats` argument of `r rdoc_url("summary()")`.

```{r using_resample_summary_stats}
## User-defined statistics function
percentiles <- function(x) quantile(x, probs = c(0.25, 0.50, 0.75))
summary(res_means, stats = percentiles)

## User-defined list of statistics functions
summary(res_means, stats = c(Mean = mean, Percentile = percentiles))
```


## Plots

Summary plots of resample output can be obtained with the `r rdoc_url("plot()")` function.  Boxplots are the default plot type; but density, errorbar, and violin plots are also available.  Plots are generated with the **ggplot2** package [@wickham:2016:GEG] and returned as `ggplot` objects.  As such, annotation and formatting defined for ggplots can be applied to the returned plots.

```{r using_resample_plots}
## Libraries for plot annotation and fomatting
library(ggplot2)
library(gridExtra)

## Individual ggplots
p1 <- plot(res_means)
p2 <- plot(res_means, type = "density")
p3 <- plot(res_means, type = "errorbar")
p4 <- plot(res_means, type = "violin")

## Grid of plots
grid.arrange(p1, p2, p3, p4, nrow = 2)
```


## Stratified Resampling

Stratification of cases for the construction of resampled training and test sets can be employed to help achieve balance across the sets.  Stratified resampling is automatically performed if variable specification is in terms of a traditional formula and will be done according to the response variable if a numeric vector or factor, the event variable if survival, and the first variable if a numeric matrix.  For model frames and recipes, stratification variables must be defined explicitly with the `strata` argument to the `r rdoc_url("ModelFrame()")` constructor or with the `r rdoc_url("role_case()", "recipe_roles")` function. 

```{r using_resample_strata, results="hide"}
## Model frame with case status stratification
mf <- ModelFrame(surv_fo, data = surv_train, strata = surv_train$status)
resample(mf, model = GBMModel)

## Recipe with case status stratification
rec <- recipe(time + status ~ ., data = surv_train) %>%
  role_surv(time = time, event = status) %>%
  role_case(stratum = status)
resample(rec, model = GBMModel)
```


## Dynamic Model Parameters

As discussed previously in the *Model Fit and Prediction* section, dynamic model parameters are evaluated at the time of model fitting and can depend on the number of observations in the fitted dataset.  In the context of resampling, dynamic parameters are repeatedly evaluated at each fit of the resampled datasets.  As such, their values can change based on the observations selected for training at each iteration of the resampling algorithm.

```{r using_resample_dynamic, results="hide"}
## Dynamic model parameter k = log number of training set observations
resample(surv_fo, data = surv_train, model = CoxStepAICModel(k = .(log(nobs))))
```


## Model Comparisons

Resampled metrics from different models can be combined for comparison with the `r rdoc_url("c()", "combine")` function.  Optional names given on the left hand side of equal operators within `r rdoc_url("c()", "combine")` calls will be used as labels in output from the `r rdoc_url("summary()")` and `r rdoc_url("plot()")` functions.  For comparisons of resampled output, the same control structure must be used in all associated calls to `r rdoc_url("resample()")` to ensure that resulting model metrics are computed on the same resampled training and test sets.  The combined resample output can be summarized and plotted as usual.

```{r using_resample_comparisons}
## Resample estimation
res1 <- resample(surv_fo, data = surv_train, model = GBMModel(n.trees = 25),
                 control = surv_means_control)
res2 <- resample(surv_fo, data = surv_train, model = GBMModel(n.trees = 50),
                 control = surv_means_control)
res3 <- resample(surv_fo, data = surv_train, model = GBMModel(n.trees = 100),
                 control = surv_means_control)

## Combine resample output for comparison
(res <- c(GBM1 = res1, GBM2 = res2, GBM3 = res3))

summary(res)

plot(res)
```

Pairwise model differences for each metric can be calculated with the `r rdoc_url("diff()")` function applied to results from a call to `r rdoc_url("c()", "combine")`.  Resulting differences can be summarized descriptively with the `r rdoc_url("summary()")` and `r rdoc_url("plot()")` functions and assessed for statistical significance with pairwise t-test performed by the `r rdoc_url("t.test()")` function.

```{r using_resample_diff}
## Pairwise model comparisons
(res_diff <- diff(res))

summary(res_diff)

plot(res_diff)
```

```{r using_resample_diff_test}
t.test(res_diff)
```
