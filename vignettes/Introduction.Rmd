---
title: "Introduction to the MachineShop Package"
author: "Brian J Smith"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: bibliography.bib
vignette: >
  %\VignetteIndexEntry{Introduction to the MachineShop Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE,
  fig.width = 7,
  fig.height = 4,
  fig.align = "center"
)

library(kableExtra)
```


## The MachineShop Package

`MachineShop` is a meta-package for machine learning with a common interface for model fitting, prediction, performance assessment, and presentation of results.  Support is provided for predictive modeling of numerical, categorical, and censored time-to-event outcomes and for resample (bootstrap and cross-validation) estimation of model performance.  This vignette introduces the package interface with a survival data analysis example, followed by applications to other types of response variables, supported methods of model specification and data preprocessing, and a list of all currently available models.


## Model Fitting and Prediction

The `lung` dataset from the `survival` package [@therneau:2015:PSA] contains time, in days, to death or censoring for advanced lung cancer patients from the North Central Cancer Treatment Group.  Also provided are potential predictors of the survival outcomes.  We begin by loading the `MachineShop` and `survival` packages required for the analysis as well as the `magrittr` package [@bache:2014:MFP] for its pipe (`%>%`) operator to simplify some of the code syntax.  The dataset is split into a training set to which a survival model will be fit and a test set on which to make predictions.  A global formula `fo` relates the predictors on the right hand side to the survival outcome on the left and will be used in all of the survival models in this vignette example. 

```{r}
## Load libraries for the survival analysis
library(MachineShop)
library(survival)
library(magrittr)

## Lung cancer dataset
head(lung)

## Create training and test sets
n <- nrow(lung) * 2 / 3
train <- head(lung, n)
test <- head(lung, -n)

## Global formula for the analysis
fo <- Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno +
                           meal.cal + wt.loss
```

Generalized boosted regression models are a tree-based ensemble method that can applied to survival outcomes.  They are available in the `MachineShop` with the function `GBMModel`.  A call to the function creates an instance of the model containing any user-specified model parameters and internal machinery for model fitting, prediction, and performance assessment.  Created models can be supplied to the `fit` function to estimate a relationship (`fo`) between predictors and an outcome based on a set of data (`train`).  The importance of variables in a model fit is estimated with the `varimp` function and plotted with `plot`.  Variable importance is a measure of the relative importance of predictors in a model and has a default range of 0 to 100, where 0 corresponds to the least important variables and 100 the most.

```{r}
## Fit a generalized boosted model
gbmfit <- fit(GBMModel(), fo, train)

## Predictor variable importance
(vi <- varimp(gbmfit))

plot(vi)
```

From the model fit, predictions are obtained at 180, 360, and 540 days as survival probabilities (`type = "prob"`) and as 0-1 death indicators (default: `type = "response"`).

```{r}
## Predict survival probabilities and outcomes at specified follow-up times
times <- c(180, 360, 540)
predict(gbmfit, test, times = times, type = "prob") %>% head

predict(gbmfit, test, times = times) %>% head
```

A call to `modelmetrics` with observed and predicted outcomes will produce model performance metrics.  The metrics produced will depend on the type of the observed variable.  In this case of a `Surv` variable, the metrics are area under the ROC curve [@heagerty:2004:TDR] and Brier score [@graf:1999:ACP] at the specified times and their time-integrated averages.

```{r}
## Model performance metrics
obs <- response(fo, test)
pred <- predict(gbmfit, test, times = times, type = "prob")
modelmetrics(obs, pred, survtimes = times)
```


## Resample Estimation of Model Performance

The performance of a model can be estimated with resampling methods that simulate repeated training and test set fits and prediction.  Performance metrics are computed on each resample to produce an empirical distribution for inference.  Resampling is controlled in the `MachineShop` with the functions:

BootControl
  : Simple bootstrap resampling.  Models are fit with bootstrap resampled training sets and used to predict the full data set.

CVControl
  : Repeated K-fold cross-validation.  The full data set is repeatedly partitioned into K-folds.  Within replicates, prediction is performed on each of the K folds with models fit on all remaining folds.

OOBControl
  : Out-of-bag bootstrap resampling.  Models are fit with bootstrap resampled training sets and used to predict the unsampled cases.
  
In our example, performance of models to predict survival at 180, 360, and 540 days will be estimated with five repeats of 10-fold cross-validation.  Variable `metrics` is defined for the purpose of reducing the printed and plotted output in this vignette to only the time-integrated ROC and Brier metrics.  Such subsetting of output would not be done in practice if there is interest in looking at all metrics.

```{r}
## Control parameters for repeated K-fold cross-validation
control <- CVControl(
  folds = 10,
  repeats = 5,
  survtimes = c(180, 360, 540)
)

## Metrics of interest
metrics <- c("ROC", "Brier")
```


### Single Model

Resampling of a single model is performed with the `resample` function applied to a model object (e.g. `GMBModel()`) and a control object like the one defined previously (`control`).  Summary statistics and plots can be obtained with the `summary` and `plot` functions.

```{r}
## Resample estimation
(perf <- resample(GBMModel(), fo, lung, control))

summary(perf)

plot(perf, metrics = metrics)
```

### Model Comparisons

Resampled metrics from different models can be combined for comparison with the `Resamples` function.  Names given on the left hand side of the equal operators in the call to `Resamples` will be used as labels in output from the `summary` and `plot` functions.  For these types of model comparisons, the same control structure should be used in all associated calls to `resample` to ensure that the resulting model metrics are computed on the same resampled training and test sets.

```{r}
## Resample estimation
gbmperf1 <- resample(GBMModel(n.trees = 25), fo, lung, control)
gbmperf2 <- resample(GBMModel(n.trees = 50), fo, lung, control)
gbmperf3 <- resample(GBMModel(n.trees = 100), fo, lung, control)

## Combine resamples for comparison
(perf <- Resamples(GBM1 = gbmperf1, GBM2 = gbmperf2, GBM3 = gbmperf3))

summary(perf)[, , metrics]

plot(perf, metrics = metrics)
plot(perf, metrics = metrics, type = "density")
plot(perf, metrics = metrics, type = "errorbar")
plot(perf, metrics = metrics, type = "violin")
```

Pairwise model differences for each metric can be calculated with the `diff` function applied to results from a call to `Resamples`.  The differences can be summarized descriptively with the `summary` and `plot` functions and assessed for statistical significance with the `t.test` function.

```{r}
## Pairwise model comparisons
(perfdiff <- diff(perf))

summary(perfdiff)[, , metrics]

plot(perfdiff, metrics = metrics)
t.test(perfdiff)[, , metrics]
```


### Model Tuning

Modelling functions may have arguments that define parameters in their model fitting algorithms.  For example, `GBMModel` has arguments `n.trees`, `interaction.dept`, and `n.minobsinnode` that defined the number of decision trees to fit, the maximum depth of variable interactions, and the minimum number of observations in the trees terminal nodes.  The `tune` function is available in the `MachineShop` to fit a model over a grid of parameters and return the model whose parameters provide the optimal fit.  Note that the function name `GBMModel`, and not the function call `GBMModel()`, is supplied as the first argument to `tune`.  Summary statistics and plots of performance across all tuning parameters are available with the `summary` and `plot` functions.

```{r}
## Tune over a grid of model parameters
(gbmtune <- tune(GBMModel, fo, lung, control,
                 grid = expand.grid(n.trees = c(25, 50, 100),
                                    interaction.depth = 1:3,
                                    n.minobsinnode = c(5, 10))))

summary(gbmtune)[, , metrics]

plot(gbmtune, type = "line", metrics = metrics)
```

The value returned by `tune` contains an object produced by a call to the modelling function with the the optimal tuning parameters.  Thus, the value can be passed on to the `fit` function for model fitting to a set of data.

```{r}
## Fit the tuned model
gbmfit <- fit(gbmtune, fo, lung)
(vi <- varimp(gbmfit))

plot(vi)
```


### Parallel Computing

Resampling is implemented with the `foreach` package [@microsoft:2017:FPF] and will run in parallel if a compatible backend is loaded, such as that provided by the `doParallel` package [@microsoft:2017:DFP].

```{r eval = FALSE}
library(doParallel)
registerDoParallel(cores = 4)
```


## Response Variable Types

### Categorical

Categorical responses with two or more levels should be code as a `factor` variable for analysis.  The type of metrics return will depend on the number of factor levels.  Metrics for factors with two levels are as follows.

Accuracy
  : Proportion of correctly classified responses.

Kappa
  : Cohen's kappa statistic measuring relative agreement between observed and predicted classifications.

Brier
  : Brier score.

ROCAUC
  : Area under the ROC curve.

PRAUC
  : Area under the precision-recall curve.
  
Sensitivity
  : Proportion of correctly classified values in the second factor level.
  
Specificity
  : Proportion of correctly classified values in the first factor level.

Index
  : A tradeoff function of sensitivity and specificity as defined by `index.cutoff` in the resampling control functions (default: Sensitivity + Specificity).  The function allows for specification of tradeoffs [@perkins:2006:IOC] other than the default of Youden's J statistic [@youden:1950:IRD].
  
Brier, ROCAUC, and PRAUC are computed directly on predicted class probabilities.  The others are computed on predicted class membership.  Memberships are defined to be in the second factor level if predicted probabilities are greater than a cutoff value defined in the resampling control functions (default: `cutoff = 0.5`).

```{r}
### Pima Indians diabetes statuses (2 levels)
library(MASS)
df <- Pima.tr
df$type <- factor(df$type)
perf <- resample(GBMModel(), type ~ ., df)
summary(perf)
```

Metrics for factors with three or more levels are as described below.

Accuracy
  : Proportion of correctly classified responses.

Kappa
  : Cohen's kappa statistic measuring relative agreement between observed and predicted classifications.

WeightedKappa
  : Weighted Cohen's kappa with equally spaced weights.  This metric is appropriate for ordered factor levels.
  
MLogLoss
  : Multinomial logistic loss or cross entropy loss.
  
MLogLoss is computed directly on predicted class probabilities.  The others are computed on predicted class membership, defined as the factor level with the highest predicted probability.

```{r}
### Iris flowers species (3 levels)
df <- iris
df$Species <- factor(df$Species)
perf <- resample(GBMModel(), Species ~ ., df)
summary(perf)
```


### Numerical

Numerical responses should be coded as a `numeric` variable.  Associated performance metrics are as defined below and illustrated with Boston housing price data [@venables:2002:MAS].

R2
  : One minus residual divided by total sums of squares,
  $$R^2 = 1 - \frac{\sum_{i=1}^n(y_i - \hat{y}_i)^2}{\sum_{i=1}^n(y_i - \bar{y})^2},$$
  where $y_i$ and $\hat{y}_i$ are the $n$ observed and predicted responses.

RMSE
  : Root mean square error,
  $$RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^n(y_i - \hat{y}_i)^2}.$$
  
MAE
  : Median absolute error,
  $$MAE = \operatorname{median}(|y_i - \operatorname{median}(y)|).$$

```{r}
### Boston housing prices
library(MASS)
perf <- resample(GBMModel(), medv ~ ., Boston)
summary(perf)
```


### Survival

Survival responses should be coded as a `Surv` variable.  In addition to the ROC and Brier survival metrics described earlier in the vignette, the concordance index [@harrell:1982:EYM] can be obtained if follow-up times are not specified for the prediction.

```{r}
## Censored lung cancer survival times
library(survival)
perf <- resample(GBMModel(), Surv(time, status) ~ ., lung)
summary(perf)
```


## Model Specifications

Model specification here refers to the relationship between the response and predictor variables and the data used to estimate it.  Three main types of specification are supported by the `fit`, `resample`, and `tune` functions: formulas, model frames, and recipes.

### Formulas

Models may be specified with the traditional formula and data frame pair, as was done in the previous examples.  In this specification, in-line functions, interactions, and `.` substitution of variables not already appearing in the formula may be include.

```{r}
## Formula specification
gbmfit <- fit(GBMModel(), medv ~ ., data = Boston)
varimp(gbmfit)
```

### Model Frames

The second specification is similar to the first, except the formula and data frame pair are give in a `model.frame`.  The model frame approach has a few subtle advantages.  One is that cases with missing values on any of the response or predictor variables are excluded from the model frame by default.  This is often desirable for models that cannot handle missing values.  Note, however, that some models like `GBMModel` do accommodate missing values.  For those, missing values can be retained in the model frame by setting its argument `na.action = NULL`.

```{r}
## Model frame specification
mf <- model.frame(medv ~ ., data = Boston)
gbmfit <- fit(GBMModel(), mf)
varimp(gbmfit)
```

Another advantage is that case weights can be included in the model frame and will be passed on to the model fitting functions in the `MachineShop`.

```{r}
## Model frame specification with case weights
mf <- model.frame(ncases / (ncases + ncontrols) ~ agegp + tobgp + alcgp,
                  data = esoph, weights = ncases + ncontrols)
gbmfit <- fit(GBMModel(), mf)
varimp(gbmfit)
```


### Recipes

The `recipes` package [@kuhn:2018:RPT] provides a framework for defining predictor and response variables and preprocessing steps to be applied to them prior to model fitting.  Using recipes helps to ensure that estimation of predictive performance accounts for all modeling step.  They are also a very convenient way of consistently applying preprocessing to new data.  Recipes currently support `factor` and `numeric` responses, but not generally `Surv`.

```{r}
## Recipe specification
library(recipes)
rec <- recipe(medv ~ ., data = Boston) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  step_pca(all_predictors())
gbmfit <- fit(GBMModel(), rec)
varimp(gbmfit)
```


### Available Models

Currently available model functions are summarized in the table below according to the types of response variables with which each model can be used.  The package additionally supplies a generic `MLModel` function for users to create their own custom models.

```{r echo = FALSE}
df <- data.frame(factor = character(), numeric = character(), ordered = character(), Surv = character(), stringsAsFactors = FALSE)

modelnames <- c("C50Model", "CForestModel", "CoxModel", "CoxStepAICModel", "GLMModel", "GLMStepAICModel", "GBMModel", "GLMNetModel", "NNetModel", "PLSModel", "POLRModel", "RandomForestModel", "SurvRegModel", "SurvRegStepAICModel", "SVMModel")

for(modelname in modelnames) {
  model <- get(modelname)()
  df[modelname,] <- ifelse(names(df) %in% model@types, "x", "")
}

kable(df, align = "c") %>%
  kable_styling("striped", full_width = FALSE, position = "center") %>%
  add_header_above(c(" " = 1, "Response Variable Types" = 4))
```


## References
