<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Using MachineShop</title>

<script src="site_libs/header-attrs-2.20/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MachineShop for R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="using.html">Using</a>
</li>
<li>
  <a href="reference.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="example_info.html">Model and Metric Information</a>
    </li>
    <li>
      <a href="example_variables.html">Variable Specifications and Preprocessing</a>
    </li>
    <li>
      <a href="example_settings.html">Global Settings</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="example_ichomes.html">IC Home Prices</a>
    </li>
    <li>
      <a href="example_iris.html">Iris Flowers Species</a>
    </li>
    <li>
      <a href="example_pima.html">Pima Indians Diabetes</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/brian-j-smith/MachineShop">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Using MachineShop</h1>

</div>


<div id="melanoma-example" class="section level1">
<h1>Melanoma Example</h1>
<p>Use of the <strong>MachineShop</strong> package is demonstrated with
a survival analysis example in which the response variable is a censored
time to event outcome. Since survival outcomes are a combination of
numerical (time to event) and categorical (event) variables, package
features for both variable types are illustrated with the example.
Support for outcomes other than survival, including nominal and ordinal
factors as well as numeric vectors and matrices, is also discussed.</p>
<p>Survival analysis is performed with the <code>Melanoma</code> dataset
from the <strong>MASS</strong> package <span class="citation">(Andersen
et al. 1993)</span>. This dataset provides survival time, in days, from
disease treatment to (1) death from disease, (2) alive at study
termination, or (3) death from other causes for 205 Denmark patients
with malignant melanomas. Also provided are potential predictors of the
survival outcomes. The analysis begins by loading required packages
<strong>MachineShop</strong>, <strong>survival</strong> <span
class="citation">(Therneau 2020)</span>, and <strong>MASS</strong>. For
the analysis, a binary overall survival outcome is created by combining
the two death categories (1 and 3) into one.</p>
<pre class="r"><code>## Analysis libraries and dataset
library(MachineShop)
library(survival)
data(Melanoma, package = &quot;MASS&quot;)

## Malignant melanoma analysis dataset
surv_df &lt;- within(Melanoma, {
  y &lt;- Surv(time, status != 2)
  remove(time, status)
})</code></pre>
<p>Descriptive summaries of the study variables are given below in Table
1, followed by a plot of estimated overall survival probabilities and
95% confidence intervals.</p>
<center>
Table 1. Variable summaries for the Melanoma survival analysis example.
</center>
<table class="table table-striped table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Characteristic
</th>
<th style="text-align:center;">
Value
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Number of subjects
</td>
<td style="text-align:center;">
205
</td>
</tr>
<tr grouplength="1">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>time</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Median (Range)
</td>
<td style="text-align:center;">
2005 (10, 5565)
</td>
</tr>
<tr grouplength="2">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>status</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
1 = Dead
</td>
<td style="text-align:center;">
71 (34.63%)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
0 = Alive
</td>
<td style="text-align:center;">
134 (65.37%)
</td>
</tr>
<tr grouplength="2">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>sex</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
1 = Male
</td>
<td style="text-align:center;">
79 (38.54%)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
0 = Female
</td>
<td style="text-align:center;">
126 (61.46%)
</td>
</tr>
<tr grouplength="1">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>age</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Median (Range)
</td>
<td style="text-align:center;">
54 (4, 95)
</td>
</tr>
<tr grouplength="1">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>year</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Median (Range)
</td>
<td style="text-align:center;">
1970 (1962, 1977)
</td>
</tr>
<tr grouplength="1">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>thickness</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Median (Range)
</td>
<td style="text-align:center;">
1.94 (0.10, 17.42)
</td>
</tr>
<tr grouplength="2">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>ulcer</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
1 = Presence
</td>
<td style="text-align:center;">
90 (43.9%)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
0 = Absence
</td>
<td style="text-align:center;">
115 (56.1%)
</td>
</tr>
</tbody>
</table>
<p><img src="using_files/figure-html/using_example_survfit-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>For the analyses, the dataset is split into a training set on which
survival models will be fit and a test set on which predictions will be
made and performance evaluated. A global formula <code>surv_fo</code> is
defined to relate the predictors on the right hand side to the overall
survival outcome on the left and will be used for all subsequent
survival models.</p>
<pre class="r"><code>## Training and test sets
set.seed(123)
train_indices &lt;- sample(nrow(surv_df), nrow(surv_df) * 2 / 3)
surv_train &lt;- surv_df[train_indices, ]
surv_test &lt;- surv_df[-train_indices, ]

## Global formula for the analysis
surv_fo &lt;- y ~ sex + age + year + thickness + ulcer</code></pre>
</div>
<div id="model-fit-and-prediction" class="section level1">
<h1>Model Fit and Prediction</h1>
<div id="model-information" class="section level2">
<h2>Model Information</h2>
<p>Model fitting requires user specification of a
<strong>MachineShop</strong> compatible model. A named list of
package-supplied models can be obtained interactively with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/modelinfo"><code>modelinfo()</code></a>
function, and includes the following components for each.</p>
<dl>
<dt><code>label</code></dt>
<dd>
character descriptor for the model.
</dd>
<dt><code>packages</code></dt>
<dd>
character vector of source packages required to use the model. These
need only be installed with the <code>install.packages()</code> function
or by equivalent means; but need not be loaded with, for example, the
<code>library()</code> function.
</dd>
<dt><code>response_types</code></dt>
<dd>
character vector of response variable types supported by the model.
</dd>
<dt><code>weights</code></dt>
<dd>
logical value or vector of the same length as
<code>response_types</code> indicating whether case weights are
supported for the responses.
</dd>
<dt><code>na.rm</code></dt>
<dd>
character sting specifying removal of <code>"all"</code> cases with
missing values from model fitting, <code>"none"</code>, or only those
whose missing values are in the <code>"response"</code> variable.
</dd>
<dt><code>arguments</code></dt>
<dd>
closure with the argument names and corresponding default values of the
model function.
</dd>
<dt><code>grid</code></dt>
<dd>
logical indicating whether automatic generation of tuning parameter
grids is implemented for the model.
</dd>
<dt><code>varimp</code></dt>
<dd>
logical indicating whether model-specific variable importance is
defined.
</dd>
</dl>
<p>Function <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/modelinfo"><code>modelinfo()</code></a>
may be called without arguments, with one or more model functions,
observed response variables, or vectors representing response variable
types; and will return information on all matching models.</p>
<pre class="r"><code>## All available models
modelinfo() %&gt;% names
#&gt;  [1] &quot;AdaBagModel&quot;         &quot;AdaBoostModel&quot;       &quot;BARTMachineModel&quot;   
#&gt;  [4] &quot;BARTModel&quot;           &quot;BlackBoostModel&quot;     &quot;C50Model&quot;           
#&gt;  [7] &quot;CForestModel&quot;        &quot;CoxModel&quot;            &quot;CoxStepAICModel&quot;    
#&gt; [10] &quot;EarthModel&quot;          &quot;FDAModel&quot;            &quot;GAMBoostModel&quot;      
#&gt; [13] &quot;GBMModel&quot;            &quot;GLMBoostModel&quot;       &quot;GLMModel&quot;           
#&gt; [16] &quot;GLMStepAICModel&quot;     &quot;GLMNetModel&quot;         &quot;KNNModel&quot;           
#&gt; [19] &quot;LARSModel&quot;           &quot;LDAModel&quot;            &quot;LMModel&quot;            
#&gt; [22] &quot;MDAModel&quot;            &quot;NaiveBayesModel&quot;     &quot;NNetModel&quot;          
#&gt; [25] &quot;ParsnipModel&quot;        &quot;PDAModel&quot;            &quot;PLSModel&quot;           
#&gt; [28] &quot;POLRModel&quot;           &quot;QDAModel&quot;            &quot;RandomForestModel&quot;  
#&gt; [31] &quot;RangerModel&quot;         &quot;RFSRCModel&quot;          &quot;RPartModel&quot;         
#&gt; [34] &quot;SelectedModel&quot;       &quot;StackedModel&quot;        &quot;SuperModel&quot;         
#&gt; [37] &quot;SurvRegModel&quot;        &quot;SurvRegStepAICModel&quot; &quot;SVMModel&quot;           
#&gt; [40] &quot;SVMANOVAModel&quot;       &quot;SVMBesselModel&quot;      &quot;SVMLaplaceModel&quot;    
#&gt; [43] &quot;SVMLinearModel&quot;      &quot;SVMPolyModel&quot;        &quot;SVMRadialModel&quot;     
#&gt; [46] &quot;SVMSplineModel&quot;      &quot;SVMTanhModel&quot;        &quot;TreeModel&quot;          
#&gt; [49] &quot;TunedModel&quot;          &quot;XGBModel&quot;            &quot;XGBDARTModel&quot;       
#&gt; [52] &quot;XGBLinearModel&quot;      &quot;XGBTreeModel&quot;</code></pre>
<p>Information is displayed below for the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel()</code></a>
function corresponding to a generalized boosted regression model, which
is applicable to survival outcomes.</p>
<pre class="r"><code>## Model-specific information
modelinfo(GBMModel)
#&gt; $GBMModel
#&gt; $GBMModel$label
#&gt; [1] &quot;Generalized Boosted Regression&quot;
#&gt; 
#&gt; $GBMModel$packages
#&gt; [1] &quot;gbm&quot;
#&gt; 
#&gt; $GBMModel$response_types
#&gt; [1] &quot;factor&quot;         &quot;numeric&quot;        &quot;PoissonVariate&quot; &quot;Surv&quot;          
#&gt; 
#&gt; $GBMModel$weights
#&gt; [1] TRUE
#&gt; 
#&gt; $GBMModel$na.rm
#&gt; [1] &quot;response&quot;
#&gt; 
#&gt; $GBMModel$arguments
#&gt; function (distribution = character(), n.trees = 100, interaction.depth = 1, 
#&gt;     n.minobsinnode = 10, shrinkage = 0.1, bag.fraction = 0.5) 
#&gt; NULL
#&gt; 
#&gt; $GBMModel$grid
#&gt; [1] TRUE
#&gt; 
#&gt; $GBMModel$varimp
#&gt; [1] TRUE</code></pre>
<p>Submitting the model function at the console will result in similar
information being displayed as formatted text.</p>
<pre class="r"><code>GBMModel
#&gt; --- MLModelFunction object -------------------------------------------------------------------------
#&gt; 
#&gt; Model name: GBMModel
#&gt; Label: Generalized Boosted Regression
#&gt; Package: gbm
#&gt; Response types: factor, numeric, PoissonVariate, Surv
#&gt; Case weights support: TRUE
#&gt; Missing case removal: response
#&gt; Tuning grid: TRUE
#&gt; Variable importance: TRUE
#&gt; 
#&gt; Arguments:
#&gt; function (distribution = character(), n.trees = 100, interaction.depth = 1, 
#&gt;     n.minobsinnode = 10, shrinkage = 0.1, bag.fraction = 0.5) 
#&gt; NULL</code></pre>
<div id="type-specific-models" class="section level3">
<h3>Type-Specific Models</h3>
<p>When data objects are supplied as arguments to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/modelinfo"><code>modelinfo()</code></a>,
information is returned on all models applicable to response variables
of the same data types. If model functions are additionally supplied as
arguments, information on the subset matching the data types is
returned.</p>
<pre class="r"><code>## All survival response-specific models
modelinfo(Surv(0)) %&gt;% names
#&gt;  [1] &quot;BARTModel&quot;           &quot;BlackBoostModel&quot;     &quot;CForestModel&quot;       
#&gt;  [4] &quot;CoxModel&quot;            &quot;CoxStepAICModel&quot;     &quot;GAMBoostModel&quot;      
#&gt;  [7] &quot;GBMModel&quot;            &quot;GLMBoostModel&quot;       &quot;GLMNetModel&quot;        
#&gt; [10] &quot;ParsnipModel&quot;        &quot;RangerModel&quot;         &quot;RFSRCModel&quot;         
#&gt; [13] &quot;RPartModel&quot;          &quot;SelectedModel&quot;       &quot;StackedModel&quot;       
#&gt; [16] &quot;SuperModel&quot;          &quot;SurvRegModel&quot;        &quot;SurvRegStepAICModel&quot;
#&gt; [19] &quot;TunedModel&quot;          &quot;XGBModel&quot;            &quot;XGBDARTModel&quot;       
#&gt; [22] &quot;XGBLinearModel&quot;      &quot;XGBTreeModel&quot;

## Identify survival response-specific models
modelinfo(Surv(0), CoxModel, GBMModel, SVMModel) %&gt;% names
#&gt; [1] &quot;CoxModel&quot; &quot;GBMModel&quot;</code></pre>
</div>
<div id="response-variable-specific-models" class="section level3">
<h3>Response Variable-Specific Models</h3>
<p>As a special case of type-specific arguments, existing response
variables to be used in analyses may be given as arguments to identify
applicable models.</p>
<pre class="r"><code>## Models for a responses variable
modelinfo(surv_df$y) %&gt;% names
#&gt;  [1] &quot;BARTModel&quot;           &quot;BlackBoostModel&quot;     &quot;CForestModel&quot;       
#&gt;  [4] &quot;CoxModel&quot;            &quot;CoxStepAICModel&quot;     &quot;GAMBoostModel&quot;      
#&gt;  [7] &quot;GBMModel&quot;            &quot;GLMBoostModel&quot;       &quot;GLMNetModel&quot;        
#&gt; [10] &quot;ParsnipModel&quot;        &quot;RangerModel&quot;         &quot;RFSRCModel&quot;         
#&gt; [13] &quot;RPartModel&quot;          &quot;SelectedModel&quot;       &quot;StackedModel&quot;       
#&gt; [16] &quot;SuperModel&quot;          &quot;SurvRegModel&quot;        &quot;SurvRegStepAICModel&quot;
#&gt; [19] &quot;TunedModel&quot;          &quot;XGBModel&quot;            &quot;XGBDARTModel&quot;       
#&gt; [22] &quot;XGBLinearModel&quot;      &quot;XGBTreeModel&quot;</code></pre>
</div>
</div>
<div id="fit-function" class="section level2">
<h2>Fit Function</h2>
<p>Package models, such as <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>,
can be specified in the <code>model</code> argument of the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/fit"><code>fit()</code></a>
function to estimate a relationship (<code>surv_fo</code>) between
predictors and an outcome based on a set of data
(<code>surv_train</code>). Argument specifications may be in terms of a
model function, function name, or object.</p>
<pre class="r"><code>## Generalized boosted regression fit

## Model function
surv_fit &lt;- fit(surv_fo, data = surv_train, model = GBMModel)

## Model function name
fit(surv_fo, data = surv_train, model = &quot;GBMModel&quot;)

## Model object
fit(surv_fo, data = surv_train, model = GBMModel(n.trees = 100, interaction.depth = 1))</code></pre>
<p>Model function arguments will assume their default values unless
otherwise changed in a function call.</p>
</div>
<div id="dynamic-model-parameters" class="section level2">
<h2>Dynamic Model Parameters</h2>
<p><em>Dynamic model parameters</em> are model function arguments
defined as expressions to be evaluated at the time of model fitting. As
such, their values can change based on characteristics of the analytic
dataset, including the number of observations or predictor variables.
Expressions to dynamic parameters are specified within the
package-supplied quote operator <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/quote"><code>.()</code></a>
and can include the following objects:</p>
<dl>
<dt><code>nobs</code></dt>
<dd>
number of observations in <code>data</code>.
</dd>
<dt><code>nvars</code></dt>
<dd>
number of predictor variables in <code>data</code>.
</dd>
<dt><code>y</code></dt>
<dd>
response variable.
</dd>
</dl>
<p>In the example below, Bayesian information criterion (BIC) based
stepwise variable selection is performed by creating a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/CoxModel"><code>CoxStepAICModel</code></a>
with dynamic parameter <code>k</code> to be calculated as the log number
of observations in the fitted dataset.</p>
<pre class="r"><code>## Dynamic model parameter k = log number of observations

## Number of observations: nobs
fit(surv_fo, data = surv_train, model = CoxStepAICModel(k = .(log(nobs))))

## Response variable: y
fit(surv_fo, data = surv_train, model = CoxStepAICModel(k = .(log(length(y)))))</code></pre>
</div>
<div id="predict-function" class="section level2">
<h2>Predict Function</h2>
<p>A <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/predict"><code>predict()</code></a>
function is supplied for application to model fit results to obtain
predicted values on a dataset specified with its <code>newdata</code>
argument or on the original dataset if not specified. Survival means are
predicted for survival outcomes by default. Estimates of the associated
survival distributions are needed to calculate the means. For models,
like <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>,
that perform semi- or non-parametric survival analysis, Weibull
approximations to the survival distributions are the default for mean
estimation. Other choices of distributional approximations are
exponential, Rayleigh, and empirical. Empirical distributions are
applicable to Cox proportional hazards-based models and can be
calculated with the method of Breslow <span
class="citation">(1972)</span> or Efron <span class="citation">(1977,
default)</span>. Note, however, that empirical survival means are
undefined mathematically if an event does not occur at the longest
follow-up time. In such situations, a restricted survival mean is
calculated by changing the longest follow-up time to an event, as
suggested by Efron <span class="citation">(1967)</span>, which will be
negatively biased.</p>
<pre class="r"><code>## Predicted survival means (default: Weibull distribution)
predict(surv_fit, newdata = surv_test)
#&gt; --- SurvMeans object -------------------------------------------------------------------------------
#&gt;  [1]   980.6427  8355.2097 19092.0713  1657.1081  2435.7916  7423.9210
#&gt;  [7]   980.6427   765.2302  3002.7963  3544.1334
#&gt; ... with 59 more values
#&gt; Distribution: weibull

## Predicted survival means (empirical distribution)
predict(surv_fit, newdata = surv_test, distr = &quot;empirical&quot;)
#&gt; --- SurvMeans object -------------------------------------------------------------------------------
#&gt;  [1] 1237.336 4806.528 5275.550 2174.870 2982.527 4699.455 1237.336  936.588
#&gt;  [9] 3399.671 3703.666
#&gt; ... with 59 more values
#&gt; Distribution: empirical</code></pre>
<p>In addition to survival means, predicted survival probabilities
(<code>type = "prob"</code>) or 0-1 survival events (default:
<code>type = "response"</code>) can be obtained with the follow-up
<code>times</code> argument. The cutoff probability for classification
of survival events (or other binary responses) can be set optionally
with the <code>cutoff</code> argument (default:
<code>cutoff = 0.5</code>). As with mean estimation, distributional
approximations to the survival functions may be specified for the
predictions, with the default for survival probabilities being the
empirical distribution.</p>
<pre class="r"><code>## Predict survival probabilities and events at specified follow-up times
surv_times &lt;- 365 * c(5, 10)

predict(surv_fit, newdata = surv_test, times = surv_times, type = &quot;prob&quot;)
#&gt; --- SurvProbs object -------------------------------------------------------------------------------
#&gt;            Time1      Time2
#&gt;  [1,] 0.17831449 0.05242217
#&gt;  [2,] 0.88497752 0.81143387
#&gt;  [3,] 0.95693579 0.92748997
#&gt;  [4,] 0.40584818 0.21394117
#&gt;  [5,] 0.57104030 0.38361499
#&gt;  [6,] 0.86814014 0.78521296
#&gt;  [7,] 0.17831449 0.05242217
#&gt;  [8,] 0.09609059 0.01821231
#&gt;  [9,] 0.64879179 0.47719578
#&gt; [10,] 0.70290781 0.54725952
#&gt; ... with 59 more rows
#&gt; Times: 1825, 3650
#&gt; Distribution: empirical

predict(surv_fit, newdata = surv_test, times = surv_times, cutoff = 0.7)
#&gt; --- SurvEvents object ------------------------------------------------------------------------------
#&gt;       Time1 Time2
#&gt;  [1,]     1     1
#&gt;  [2,]     0     0
#&gt;  [3,]     0     0
#&gt;  [4,]     1     1
#&gt;  [5,]     1     1
#&gt;  [6,]     0     0
#&gt;  [7,]     1     1
#&gt;  [8,]     1     1
#&gt;  [9,]     1     1
#&gt; [10,]     0     1
#&gt; ... with 59 more rows
#&gt; Times: 1825, 3650
#&gt; Distribution: empirical</code></pre>
<p>Prediction of other outcome types is more straightforward. Predicted
numeric and factor responses are of the same class as the observed
values at the default <code>type = "response"</code>; whereas, double
(decimal) numeric values and factor level probabilities result when
<code>type = "prob"</code>.</p>
</div>
</div>
<div id="variable-specifications" class="section level1">
<h1>Variable Specifications</h1>
<p>Variable specification defines the relationship between response and
predictor variables as well as the data used to estimate the
relationship. Four main types of specifications are supported by the
package’s <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/fit"><code>fit()</code></a>
and <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/resample"><code>resample()</code></a>
functions: traditional formula, design matrix, model frame, and
recipe.</p>
<div id="traditional-formula" class="section level2">
<h2>Traditional Formula</h2>
<p>Variables may be specified with a traditional formula and data frame
pair, as was done at the start of the survival example. This
specification allows for crossing (<code>*</code>), interaction
(<code>:</code>), and removal (<code>-</code>) of predictors in the
formula; <code>.</code> substitution of variables not already appearing
in the formula; in-line functions of response variables; and in-lining
of operators and functions of predictors.</p>
<pre class="r"><code>## Datasets
data(Pima.te, package = &quot;MASS&quot;)
data(Pima.tr, package = &quot;MASS&quot;)

## Formula specification
model_fit &lt;- fit(type ~ ., data = Pima.tr, model = GBMModel)
predict(model_fit, newdata = Pima.te) %&gt;% head
#&gt; [1] Yes No  No  No  No  Yes
#&gt; Levels: No Yes</code></pre>
<p>The syntax for traditional formulas is detailed in the
<strong>R</strong> help documentation on the <code>formula()</code>
function. However, some constraints are placed on the syntax by the
<strong>MachineShop</strong> package. Specifically, in-lining on the
right-hand side of formulas is limited to the operators and functions
listed in the <code>"RHS.formula"</code> package setting.</p>
<pre class="r"><code>settings(&quot;RHS.formula&quot;)
#&gt;  [1] &quot;!&quot;        &quot;!=&quot;       &quot;%%&quot;       &quot;%/%&quot;      &quot;%in%&quot;     &quot;&amp;&quot;       
#&gt;  [7] &quot;(&quot;        &quot;*&quot;        &quot;+&quot;        &quot;-&quot;        &quot;.&quot;        &quot;/&quot;       
#&gt; [13] &quot;:&quot;        &quot;&lt;&quot;        &quot;&lt;=&quot;       &quot;==&quot;       &quot;&gt;&quot;        &quot;&gt;=&quot;      
#&gt; [19] &quot;I&quot;        &quot;^&quot;        &quot;abs&quot;      &quot;acos&quot;     &quot;acosh&quot;    &quot;asin&quot;    
#&gt; [25] &quot;asinh&quot;    &quot;atan&quot;     &quot;atanh&quot;    &quot;ceiling&quot;  &quot;cos&quot;      &quot;cosh&quot;    
#&gt; [31] &quot;cospi&quot;    &quot;digamma&quot;  &quot;exp&quot;      &quot;expm1&quot;    &quot;floor&quot;    &quot;gamma&quot;   
#&gt; [37] &quot;lgamma&quot;   &quot;log&quot;      &quot;log1p&quot;    &quot;offset&quot;   &quot;round&quot;    &quot;sign&quot;    
#&gt; [43] &quot;signif&quot;   &quot;sin&quot;      &quot;sinh&quot;     &quot;sinpi&quot;    &quot;sqrt&quot;     &quot;tan&quot;     
#&gt; [49] &quot;tanh&quot;     &quot;tanpi&quot;    &quot;trigamma&quot; &quot;trunc&quot;    &quot;|&quot;</code></pre>
<p>This setting is intended to help avoid the definition of predictor
variable encodings that involve dataset-specific parameter calculations.
Such parameters would be calculated separated on training and test sets,
and could lead to failed calculations or improper estimates of
predictive performance. For example, the <code>factor()</code> function
is not allowed because consistency of its (default) encoding requires
that all levels be present in every dataset. Resampled datasets subset
the original cases and are thus prone to missing factor levels. For
users wishing to apply factor encodings or other encodings not available
with traditional formulas, a more flexible preprocessing recipe syntax
is supported, as described later.</p>
</div>
<div id="design-matrix" class="section level2">
<h2>Design Matrix</h2>
<p>Variables stored separately in a design matrix of predictors and
object of responses can be supplied to the fit functions directly.
Fitting with design matrices has less computational overhead than
traditional formulas and allows for greater numbers of predictor
variables in some models, including <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>,
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GLMNetModel"><code>GLMNetModel</code></a>,
and <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/RandomForestModel"><code>RandomForestModel</code></a>.</p>
<pre class="r"><code>## Example design matrix and response object
x &lt;- model.matrix(type ~ . - 1, data = Pima.tr)
y &lt;- Pima.tr$type

## Design matrix specification
model_fit &lt;- fit(x, y, model = GBMModel)
predict(model_fit, newdata = Pima.te) %&gt;% head
#&gt; [1] Yes No  No  No  No  Yes
#&gt; Levels: No Yes</code></pre>
</div>
<div id="model-frame" class="section level2">
<h2>Model Frame</h2>
<p>A <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelFrame"><code>ModelFrame</code></a>
class is defined by the package for specification of predictor and
response variables along with other attributes to control model fitting.
Model frames can be created with calls to the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelFrame"><code>ModelFrame()</code></a>
constructor function using a syntax similar to the traditional formula
or design matrix.</p>
<pre class="r"><code>## Model frame specification

## Formula
mf &lt;- ModelFrame(type ~ ., data = Pima.tr)
model_fit &lt;- fit(mf, model = GBMModel)
predict(model_fit, newdata = Pima.te) %&gt;% head
#&gt; [1] Yes No  No  No  No  Yes
#&gt; Levels: No Yes

## Design matrix
mf &lt;- ModelFrame(x, y)
model_fit &lt;- fit(mf, model = GBMModel)
predict(model_fit, newdata = Pima.te) %&gt;% head
#&gt; [1] Yes No  No  No  No  Yes
#&gt; Levels: No Yes</code></pre>
<p>The model frame approach has a few advantages over model fitting
directly with a traditional formula. One is that cases with missing
values on any of the response or predictor variables are excluded from
the model frame by default. This is often desirable for models that do
not handle missing values. Conversely, missing values can be retained in
the model frame by setting its argument <code>na.rm = FALSE</code> for
models, like <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>,
that do handle them. A second advantage is that case weights can be
included in the model frame to be passed on to the model fitting
functions.</p>
<pre class="r"><code>## Model frame specification with case weights
mf &lt;- ModelFrame(ncases / (ncases + ncontrols) ~ agegp + tobgp + alcgp, data = esoph,
                 weights = ncases + ncontrols)
fit(mf, model = GBMModel)</code></pre>
<p>A third, which will be illustrated later, is user-specification of a
variable for stratified resampling via the constructor’s
<code>strata</code> argument.</p>
</div>
<div id="preprocessing-recipe" class="section level2">
<h2>Preprocessing Recipe</h2>
<p>The <strong>recipes</strong> package <span class="citation">(Kuhn and
Wickham 2020)</span> provides a flexible framework for defining
predictor and response variables as well as preprocessing steps to be
applied to them prior to model fitting. Using recipes helps ensure that
estimation of predictive performance accounts for all modeling step.
They are also a convenient way of consistently applying preprocessing to
new data. A basic recipe is given below in terms of the formula and data
frame ingredients needed for the analysis.</p>
<pre class="r"><code>## Recipe specification
library(recipes)

rec &lt;- recipe(type ~ ., data = Pima.tr)
model_fit &lt;- fit(rec, model = GBMModel)
predict(model_fit, newdata = Pima.te) %&gt;% head
#&gt; [1] Yes No  No  No  Yes Yes
#&gt; Levels: No Yes</code></pre>
<p>As shown, prediction on new data with a model fit to a recipe is done
on an unprocessed dataset. Recipe case weights and stratified resampling
are supported with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/recipe_roles"><code>role_case()</code></a>
function. As an example, an initial step is included in the recipe below
to replace the original role of variable <code>weights</code> with a
designation of case weights. That is followed by a step to convert three
ordinal factors to integer scores.</p>
<pre class="r"><code>## Recipe specification with case weights
df &lt;- within(esoph, {
  y &lt;- ncases / (ncases + ncontrols)
  weights &lt;- ncases + ncontrols
  remove(ncases, ncontrols)
})

rec &lt;- recipe(y ~ agegp + tobgp + alcgp + weights, data = df) %&gt;%
  role_case(weight = weights, replace = TRUE) %&gt;%
  step_ordinalscore(agegp, tobgp, alcgp)
fit(rec, model = GBMModel)</code></pre>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>The variable specification approaches differ with respect to support
for preprocessing, in-line functions, case weights, resampling strata,
and computational overhead, as summarized in the table below. Only
recipes apply preprocessing steps automatically during model fitting and
should be used when it is important to account for such steps in the
estimation of model predictive performance. Preprocessing would need to
be done manually and separately otherwise. Design matrices have the
lowest computational overhead and can enable analyses involving larger
numbers of predictors than the other approaches. Both recipes and model
frames allow for user-defined case weights (default: equal) and
resampling strata (default: none). The remaining approaches are fixed to
have equal weights and strata defined by the response variable. Syntax
ranges from simplest to most complex for design matrices, traditional
formulas, model frames, and recipes, respectively. The relative
strengths of each approach should be considered within the context of a
given analysis when deciding upon which one to use.</p>
<table class="table table-striped table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Table 2. Characteristics of available variable specification approaches.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Specification
</th>
<th style="text-align:center;">
Preprocessing
</th>
<th style="text-align:center;">
In-line Functions
</th>
<th style="text-align:center;">
Case Weights
</th>
<th style="text-align:center;">
Resampling Strata
</th>
<th style="text-align:center;">
Computational Overhead
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Traditional Formula
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">manual</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">yes</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">equal</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">response</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: blue !important;">medium</span>
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Design Matrix
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">manual</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">no</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">equal</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">response</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">low</span>
</td>
</tr>
<tr grouplength="2">
<td colspan="6" style="border-bottom: 1px solid;">
<strong>Model Frame</strong>
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;padding-left: 2em;" indentlevel="1">
Traditional Formula
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">manual</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">yes</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">user</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">user</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: blue !important;">medium</span>
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;padding-left: 2em;" indentlevel="1">
Design Matrix
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">manual</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">no</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">user</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">user</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">low</span>
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Recipe
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">automatic</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">no</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">user</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green !important;">user</span>
</td>
<td style="text-align:center;">
<span
style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange !important;">high</span>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="response-variable-types" class="section level1">
<h1>Response Variable Types</h1>
<p>The <strong>R</strong> class types of response variables play a
central role in their analysis with the package. They determine, for
example, the specific models that can be fit, fitting algorithms
employed, predicted values produced, and applicable performance metrics
and analyses. As described in the following sections, factors, ordered
factors, numeric vectors and matrices, and survival objects are
supported by the package.</p>
<div id="factor" class="section level2">
<h2>Factor</h2>
<p>Categorical responses with two or more levels should be coded as a
<code>factor</code> variable for analysis. Prediction is of factor
levels by default and of level-specific probabilities if
<code>type = "prob"</code>.</p>
<pre class="r"><code>## Iris flowers species (3-level factor)
model_fit &lt;- fit(Species ~ ., data = iris, model = GBMModel)
predict(model_fit) %&gt;% head
#&gt; [1] setosa setosa setosa setosa setosa setosa
#&gt; Levels: setosa versicolor virginica
predict(model_fit, type = &quot;prob&quot;) %&gt;% head
#&gt;         setosa   versicolor    virginica
#&gt; [1,] 0.9999529 4.704617e-05 5.999170e-08
#&gt; [2,] 0.9999732 2.667703e-05 1.626995e-07
#&gt; [3,] 0.9999744 2.549026e-05 7.312256e-08
#&gt; [4,] 0.9999683 3.164919e-05 1.004487e-07
#&gt; [5,] 0.9999529 4.704617e-05 5.999170e-08
#&gt; [6,] 0.9999446 5.537937e-05 5.999120e-08</code></pre>
<p>In the case of a binary factor, the second factor level is treated as
the event and the level for which predicted probabilities are
computed.</p>
<pre class="r"><code>## Pima Indians diabetes statuses (binary factor)
data(Pima.te, package = &quot;MASS&quot;)
data(Pima.tr, package = &quot;MASS&quot;)

model_fit &lt;- fit(type ~ ., data = Pima.tr, model = GBMModel)
predict(model_fit, newdata = Pima.te) %&gt;% head
#&gt; [1] Yes No  No  No  No  Yes
#&gt; Levels: No Yes
predict(model_fit, newdata = Pima.te, type = &quot;prob&quot;) %&gt;% head
#&gt; [1] 0.84469494 0.05769275 0.03483727 0.03271784 0.48315264 0.74959442</code></pre>
</div>
<div id="ordered-factor" class="section level2">
<h2>Ordered Factor</h2>
<p>Categorical responses can be designated as having ordered levels by
storing them as an <code>ordered</code> factor variable. For categorical
vectors, this can be accomplished with the <code>factor()</code>
function and its argument <code>ordered = TRUE</code> or more simply
with the <code>ordered()</code> function. Numeric vectors can be
converted to ordered factors with the <code>cut()</code> function.</p>
<pre class="r"><code>## Iowa City housing prices (ordered factor)
df &lt;- within(ICHomes, {
  sale_amount &lt;- cut(sale_amount, breaks = 3,
                     labels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;),
                     ordered_result = TRUE)
})

model_fit &lt;- fit(sale_amount ~ ., data = df, model = GBMModel)
predict(model_fit) %&gt;% head
#&gt; [1] Low Low Low Low Low Low
#&gt; Levels: Low &lt; Medium &lt; High
predict(model_fit, type = &quot;prob&quot;) %&gt;% head
#&gt;            Low      Medium         High
#&gt; [1,] 0.9964837 0.003459652 5.669359e-05
#&gt; [2,] 0.9970031 0.002944093 5.276251e-05
#&gt; [3,] 0.9852936 0.014556622 1.498127e-04
#&gt; [4,] 0.9842968 0.015583572 1.195963e-04
#&gt; [5,] 0.9184646 0.081327684 2.077245e-04
#&gt; [6,] 0.8934669 0.106306241 2.268354e-04</code></pre>
</div>
<div id="numeric-vector" class="section level2">
<h2>Numeric Vector</h2>
<p>Code univariate numerical responses as a <code>numeric</code>
variable. Predicted numeric values are of the original type (integer or
double) by default, and doubles if <code>type = "numeric"</code>.</p>
<pre class="r"><code>## Iowa City housing prices
model_fit &lt;- fit(sale_amount ~ ., data = ICHomes, model = GBMModel)
predict(model_fit) %&gt;% head
#&gt; [1] 105664 171728 205150 120392 218505 225576
predict(model_fit, type = &quot;numeric&quot;) %&gt;% head
#&gt; [1] 105663.7 171727.6 205149.8 120392.4 218504.6 225576.3</code></pre>
</div>
<div id="numeric-matrix" class="section level2">
<h2>Numeric Matrix</h2>
<p>Store multivariate numerical responses as a numeric
<code>matrix</code> variable for model fitting with traditional formulas
and model frames.</p>
<pre class="r"><code>## Anscombe&#39;s multiple regression models dataset

## Numeric matrix response formula
model_fit &lt;- fit(cbind(y1, y2, y3) ~ x1, data = anscombe, model = LMModel)
predict(model_fit) %&gt;% head
#&gt;             y1        y2       y3
#&gt; [1,]  8.001000  8.000909 7.999727
#&gt; [2,]  7.000818  7.000909 7.000273
#&gt; [3,]  9.501273  9.500909 9.498909
#&gt; [4,]  7.500909  7.500909 7.500000
#&gt; [5,]  8.501091  8.500909 8.499455
#&gt; [6,] 10.001364 10.000909 9.998636</code></pre>
<p>For recipes, the multiple response may be defined on the left hand
side of a recipe formula or as a single variable within a data
frame.</p>
<pre class="r"><code>## Numeric matrix response recipe
## Defined in a recipe formula
rec &lt;- recipe(y1 + y2 + y3 ~ x1, data = anscombe)

## Defined within a data frame
df &lt;- within(anscombe, {
  y &lt;- cbind(y1, y2, y3)
  remove(y1, y2, y3)
})
rec &lt;- recipe(y ~ x1, data = df)
model_fit &lt;- fit(rec, model = LMModel)
predict(model_fit) %&gt;% head
#&gt;             y1        y2       y3
#&gt; [1,]  8.001000  8.000909 7.999727
#&gt; [2,]  7.000818  7.000909 7.000273
#&gt; [3,]  9.501273  9.500909 9.498909
#&gt; [4,]  7.500909  7.500909 7.500000
#&gt; [5,]  8.501091  8.500909 8.499455
#&gt; [6,] 10.001364 10.000909 9.998636</code></pre>
</div>
<div id="survival-objects" class="section level2">
<h2>Survival Objects</h2>
<p>Censored time-to-event survival responses should be stored as a
<code>Surv</code> variable for model fitting with traditional formulas
and model frames.</p>
<pre class="r"><code>## Survival response formula
library(survival)

fit(Surv(time, status) ~ ., data = veteran, model = GBMModel)</code></pre>
<p>For recipes, survival responses may be defined with the individual
survival time and event variables given on the left hand side of a
recipe formula and their roles designated with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/recipe_roles"><code>role_surv()</code></a>
function or as a single <code>Surv</code> variable within a data
frame.</p>
<pre class="r"><code>## Survival response recipe
## Defined in a recipe formula
rec &lt;- recipe(time + status ~ ., data = veteran) %&gt;%
  role_surv(time = time, event = status)

## Defined within a data frame
df &lt;- within(veteran, {
  y &lt;- Surv(time, status)
  remove(time, status)
})
rec &lt;- recipe(y ~ ., data = df)
fit(rec, model = GBMModel)</code></pre>
</div>
</div>
<div id="model-performance-metrics" class="section level1">
<h1>Model Performance Metrics</h1>
<p>Performance metrics quantify associations between observed and
predicted responses and provide a means of evaluating the predictive
performances of models.</p>
<div id="performance-function" class="section level2">
<h2>Performance Function</h2>
<p>Metrics can be computed with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/performance"><code>performance()</code></a>
function applied to observed responses and responses predicted with the
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/predict"><code>predict()</code></a>
function. In the case of observed versus predicted survival
probabilities or events, metrics will be calculated at user-specified
survival times and returned along with their time-integrated mean.</p>
<pre class="r"><code>## Survival performance metrics

## Observed responses
obs &lt;- response(surv_fit, newdata = surv_test)

## Predicted survival means
pred_means &lt;- predict(surv_fit, newdata = surv_test)
performance(obs, pred_means)
#&gt;  C-Index 
#&gt; 0.622093

## Predicted survival probabilities
pred_probs &lt;- predict(surv_fit, newdata = surv_test, times = surv_times, type = &quot;prob&quot;)
performance(obs, pred_probs)
#&gt;     Brier.Mean    Brier.Time1    Brier.Time2   ROC AUC.Mean  ROC AUC.Time1 
#&gt;      0.2775278      0.2310083      0.3240473      0.6053896      0.6091172 
#&gt;  ROC AUC.Time2  Accuracy.Mean Accuracy.Time1 Accuracy.Time2 
#&gt;      0.6016620      0.6667354      0.7207325      0.6127383

## Predicted survival events
pred_events &lt;- predict(surv_fit, newdata = surv_test, times = surv_times)
performance(obs, pred_events)
#&gt;  Accuracy.Mean Accuracy.Time1 Accuracy.Time2 
#&gt;      0.6667354      0.7207325      0.6127383</code></pre>
<p>Function <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/performance"><code>performance()</code></a>
computes a default set of metrics according to the observed and
predicted response types, as indicated and in the order given in the
table below.</p>
<p>Table 3. Default performance metrics by response types.</p>
<table>
<colgroup>
<col width="30%" />
<col width="69%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Response</th>
<th align="left">Default Metrics</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Factor</td>
<td align="left">Brier Score, Accuracy, Cohen’s Kappa</td>
</tr>
<tr class="even">
<td align="left">Binary Factor</td>
<td align="left">Brier Score, Accuracy, Cohen’s Kappa, Area Under ROC
Curve, Sensitivity, Specificity</td>
</tr>
<tr class="odd">
<td align="left">Numeric Vector or Matrix</td>
<td align="left">Root Mean Squared Error, R<sup>2</sup>, Mean Absolute
Error</td>
</tr>
<tr class="even">
<td align="left">Survival Means</td>
<td align="left">Concordance Index</td>
</tr>
<tr class="odd">
<td align="left">Survival Probabilities</td>
<td align="left">Brier Score, Area Under ROC Curve, Accuracy</td>
</tr>
<tr class="even">
<td align="left">Survival Events</td>
<td align="left">Accuracy</td>
</tr>
</tbody>
</table>
<p>These defaults may be changed by specifying one or more
package-supplied metric functions to the <code>metrics</code> argument
of <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/performance"><code>performance()</code></a>.
Specification of the <code>metrics</code> argument can be in terms of a
single metric function, function name, or list of metric functions. List
names, if specified, will be displayed as metric labels in graphical and
tabular summaries; otherwise, the function names will be used as labels
for unnamed lists.</p>
<pre class="r"><code>## Single metric function
performance(obs, pred_means, metrics = cindex)

## Single metric function name
performance(obs, pred_means, metrics = &quot;cindex&quot;)

## List of metric functions
performance(obs, pred_means, metrics = c(cindex, rmse, rmsle))

## Named list of metric functions
performance(obs, pred_means,
            metrics = c(&quot;CIndex&quot; = cindex, &quot;RMSE&quot; = rmse, &quot;RMSLE&quot; = rmsle))</code></pre>
<p>Metrics based on classification of two-level class probabilities,
like sensitivity and specificity, optionally allow for specification of
the classification cutoff probability (default:
<code>cutoff = 0.5</code>).</p>
<pre class="r"><code>## User-specified survival probability metrics
performance(obs, pred_probs, metrics = c(sensitivity, specificity), cutoff = 0.7)
#&gt;  sensitivity.Mean sensitivity.Time1 sensitivity.Time2  specificity.Mean 
#&gt;         0.4855464         0.4636436         0.5074493         0.6655982 
#&gt; specificity.Time1 specificity.Time2 
#&gt;         0.7487698         0.5824266</code></pre>
</div>
<div id="metric-functions" class="section level2">
<h2>Metric Functions</h2>
<p>Whereas multiple package-supplied metrics can be calculated
simultaneously with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/performance"><code>performance()</code></a>
function, each exists as a stand-alone function that can be called
individually.</p>
<pre class="r"><code>## Metric functions for survival means
cindex(obs, pred_means)
#&gt; [1] 0.622093

rmse(obs, pred_means)
#&gt; [1] 5463.385

rmsle(obs, pred_means)
#&gt; [1] 1.998432

## Metric functions for survival probabilities
sensitivity(obs, pred_probs)
#&gt;      Mean     Time1     Time2 
#&gt; 0.3588005 0.2895285 0.4280725

specificity(obs, pred_probs)
#&gt;      Mean     Time1     Time2 
#&gt; 0.9323417 0.8646834 1.0000000</code></pre>
</div>
<div id="metric-information" class="section level2">
<h2>Metric Information</h2>
<p>A named list of available metrics can be obtained interactively with
the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metricinfo"><code>metricinfo()</code></a>
function, and includes the following components for each one.</p>
<dl>
<dt><code>label</code></dt>
<dd>
character descriptor for the metric.
</dd>
<dt><code>maximize</code></dt>
<dd>
logical indicating whether maximization of the metric leads to better
predictive performance.
</dd>
<dt><code>arguments</code></dt>
<dd>
closure with the argument names and corresponding default values of the
metric function.
</dd>
<dt><code>response_types</code></dt>
<dd>
data frame of the observed and predicted response variable types
supported by the metric.
</dd>
</dl>
<p>Function <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metricinfo"><code>metricinfo()</code></a>
may be called without arguments, with one or more metric functions, an
observed response variable, an observed and predicted response variable
pair, response variable types, or resampled output; and will return
information on all matching metrics.</p>
<pre class="r"><code>## All available metrics
metricinfo() %&gt;% names
#&gt;  [1] &quot;accuracy&quot;        &quot;auc&quot;             &quot;brier&quot;           &quot;cindex&quot;         
#&gt;  [5] &quot;cross_entropy&quot;   &quot;f_score&quot;         &quot;fnr&quot;             &quot;fpr&quot;            
#&gt;  [9] &quot;gini&quot;            &quot;kappa2&quot;          &quot;mae&quot;             &quot;mse&quot;            
#&gt; [13] &quot;msle&quot;            &quot;npv&quot;             &quot;ppr&quot;             &quot;ppv&quot;            
#&gt; [17] &quot;pr_auc&quot;          &quot;precision&quot;       &quot;r2&quot;              &quot;recall&quot;         
#&gt; [21] &quot;rmse&quot;            &quot;rmsle&quot;           &quot;roc_auc&quot;         &quot;roc_index&quot;      
#&gt; [25] &quot;sensitivity&quot;     &quot;specificity&quot;     &quot;tnr&quot;             &quot;tpr&quot;            
#&gt; [29] &quot;weighted_kappa2&quot;</code></pre>
<p>Information is displayed below for the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>cindex()</code></a>
function corresponding to a concordance index, which is applicable to
observed survival and predicted means.</p>
<pre class="r"><code>## Metric-specific information
metricinfo(cindex)
#&gt; $cindex
#&gt; $cindex$label
#&gt; [1] &quot;Concordance Index&quot;
#&gt; 
#&gt; $cindex$maximize
#&gt; [1] TRUE
#&gt; 
#&gt; $cindex$arguments
#&gt; function (observed, predicted = NULL, weights = NULL, ...) 
#&gt; NULL
#&gt; 
#&gt; $cindex$response_types
#&gt;   observed predicted
#&gt; 1   factor   numeric
#&gt; 2 Resample      NULL
#&gt; 3     Surv   numeric</code></pre>
<p>Submitting the metric function at the console will result in similar
information being displayed as formatted text.</p>
<pre class="r"><code>cindex
#&gt; --- MLMetric object --------------------------------------------------------------------------------
#&gt; 
#&gt; Metric name: cindex
#&gt; Label: Concordance Index
#&gt; Maximize: TRUE
#&gt; 
#&gt; Arguments:
#&gt; function (observed, predicted = NULL, weights = NULL, ...) 
#&gt; NULL
#&gt; 
#&gt; Types:
#&gt;   observed predicted
#&gt; 1   factor   numeric
#&gt; 2 Resample      NULL
#&gt; 3     Surv   numeric</code></pre>
<div id="type-specific-metrics" class="section level3">
<h3>Type-Specific Metrics</h3>
<p>When data objects are supplied as arguments to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metricinfo"><code>metricinfo()</code></a>,
information is returned on all metrics applicable to response variables
of the same data types. Observed response variable type is inferred from
the first data argument and predicted type from the second, if given.
For survival responses, predicted types may be <code>numeric</code> for
survival means, <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SurvMatrix"><code>SurvEvents</code></a>
for 0-1 survival events at specified follow-up times, or <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SurvMatrix"><code>SurvProbs</code></a>
for follow-up time survival probabilities. If model functions are
additionally supplied as arguments, information on the subset matching
the data types is returned.</p>
<pre class="r"><code>## Metrics for observed and predicted response variable types
metricinfo(Surv(0)) %&gt;% names
#&gt;  [1] &quot;accuracy&quot;    &quot;auc&quot;         &quot;brier&quot;       &quot;cindex&quot;      &quot;f_score&quot;    
#&gt;  [6] &quot;fnr&quot;         &quot;fpr&quot;         &quot;gini&quot;        &quot;kappa2&quot;      &quot;mae&quot;        
#&gt; [11] &quot;mse&quot;         &quot;msle&quot;        &quot;npv&quot;         &quot;ppr&quot;         &quot;ppv&quot;        
#&gt; [16] &quot;pr_auc&quot;      &quot;precision&quot;   &quot;r2&quot;          &quot;recall&quot;      &quot;rmse&quot;       
#&gt; [21] &quot;rmsle&quot;       &quot;roc_auc&quot;     &quot;roc_index&quot;   &quot;sensitivity&quot; &quot;specificity&quot;
#&gt; [26] &quot;tnr&quot;         &quot;tpr&quot;

metricinfo(Surv(0), numeric(0)) %&gt;% names
#&gt; [1] &quot;cindex&quot; &quot;gini&quot;   &quot;mae&quot;    &quot;mse&quot;    &quot;msle&quot;   &quot;r2&quot;     &quot;rmse&quot;   &quot;rmsle&quot;

metricinfo(Surv(0), SurvEvents(0)) %&gt;% names
#&gt;  [1] &quot;accuracy&quot;    &quot;f_score&quot;     &quot;fnr&quot;         &quot;fpr&quot;         &quot;kappa2&quot;     
#&gt;  [6] &quot;npv&quot;         &quot;ppr&quot;         &quot;ppv&quot;         &quot;precision&quot;   &quot;recall&quot;     
#&gt; [11] &quot;roc_index&quot;   &quot;sensitivity&quot; &quot;specificity&quot; &quot;tnr&quot;         &quot;tpr&quot;

metricinfo(Surv(0), SurvProbs(0)) %&gt;% names
#&gt;  [1] &quot;accuracy&quot;    &quot;auc&quot;         &quot;brier&quot;       &quot;f_score&quot;     &quot;fnr&quot;        
#&gt;  [6] &quot;fpr&quot;         &quot;kappa2&quot;      &quot;npv&quot;         &quot;ppr&quot;         &quot;ppv&quot;        
#&gt; [11] &quot;pr_auc&quot;      &quot;precision&quot;   &quot;recall&quot;      &quot;roc_auc&quot;     &quot;roc_index&quot;  
#&gt; [16] &quot;sensitivity&quot; &quot;specificity&quot; &quot;tnr&quot;         &quot;tpr&quot;

## Identify survival-specific metrics
metricinfo(Surv(0), auc, cross_entropy, cindex) %&gt;% names
#&gt; [1] &quot;auc&quot;    &quot;cindex&quot;</code></pre>
</div>
<div id="response-variable-specific-metrics" class="section level3">
<h3>Response Variable-Specific Metrics</h3>
<p>Existing response variables observed and those obtained from the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/predict"><code>predict()</code></a>
function may be given as arguments to identify metrics that are
applicable to them.</p>
<pre class="r"><code>## Metrics for observed and predicted responses from model fits
metricinfo(obs, pred_means) %&gt;% names
#&gt; [1] &quot;cindex&quot; &quot;gini&quot;   &quot;mae&quot;    &quot;mse&quot;    &quot;msle&quot;   &quot;r2&quot;     &quot;rmse&quot;   &quot;rmsle&quot;

metricinfo(obs, pred_probs) %&gt;% names
#&gt;  [1] &quot;accuracy&quot;    &quot;auc&quot;         &quot;brier&quot;       &quot;f_score&quot;     &quot;fnr&quot;        
#&gt;  [6] &quot;fpr&quot;         &quot;kappa2&quot;      &quot;npv&quot;         &quot;ppr&quot;         &quot;ppv&quot;        
#&gt; [11] &quot;pr_auc&quot;      &quot;precision&quot;   &quot;recall&quot;      &quot;roc_auc&quot;     &quot;roc_index&quot;  
#&gt; [16] &quot;sensitivity&quot; &quot;specificity&quot; &quot;tnr&quot;         &quot;tpr&quot;</code></pre>
</div>
</div>
<div id="factors" class="section level2">
<h2>Factors</h2>
<p>Metrics applicable to multi-level factor response variables are
summarized below.</p>
<dl>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>accuracy()</code></a></dt>
<dd>
proportion of correctly classified responses.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>brier()</code></a></dt>
<dd>
<a href="https://en.wikipedia.org/wiki/Brier_score">Brier score</a>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>cross_entropy()</code></a></dt>
<dd>
<a href="https://en.wikipedia.org/wiki/Cross_entropy">cross entropy</a>
loss averaged over the number of cases.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>kappa2()</code></a></dt>
<dd>
<a href="https://en.wikipedia.org/wiki/Cohen%27s_kappa">Cohen’s
kappa</a> statistic measuring relative agreement between observed and
predicted classifications.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>weighted_kappa2()</code></a></dt>
<dd>
<a
href="https://en.wikipedia.org/wiki/Cohen%27s_kappa#Weighted_kappa">weighted
Cohen’s kappa</a> for ordered factor responses only.
</dd>
</dl>
<p>Brier score and cross entropy loss are computed directly on predicted
class probabilities. The other metrics are computed on predicted class
membership, defined as the factor level with the highest predicted
probability.</p>
</div>
<div id="binary-factors" class="section level2">
<h2>Binary Factors</h2>
<p>Metrics for binary factors include those given for multi-level
factors as well as the following.</p>
<dl>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>auc()</code></a></dt>
<dd>
area under a performance curve.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>cindex()</code></a></dt>
<dd>
concordance index computed as rank order agreement between predicted
probabilities for paired event and non-event cases. This metric can be
interpreted as the probability that a randomly selected event case will
have a higher predicted value than a randomly selected non-event case,
and is the same as area under the ROC curve.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>f_score()</code></a></dt>
<dd>
<a href="https://en.wikipedia.org/wiki/Precision_and_recall#F-measure">F
score</a>, <span class="math inline">\(F_\beta = (1 + \beta^2)
\frac{\text{precision} \times \text{recall}}{\beta^2 \times
\text{precision} + \text{recall}}\)</span>. F1 score <span
class="math inline">\((\beta = 1)\)</span> is the package default.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>fnr()</code></a></dt>
<dd>
false negative rate, <span class="math inline">\(FNR = \frac{FN}{TP +
FN} = 1 - TPR\)</span>.
</dd>
</dl>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Table 4. Confusion matrix of observed and predicted response
classifications.
</caption>
<thead>
<tr>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Predicted Response
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Observed Response
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Negative
</th>
<th style="text-align:center;">
Positive
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Negative
</td>
<td style="text-align:center;">
True Negative (TN)
</td>
<td style="text-align:center;">
False Negative (FN)
</td>
</tr>
<tr>
<td style="text-align:left;">
Positive
</td>
<td style="text-align:center;">
False Positive (FP)
</td>
<td style="text-align:center;">
True Positive (TP)
</td>
</tr>
</tbody>
</table>
<dl>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>fpr()</code></a></dt>
<dd>
false positive rate, <span class="math inline">\(FPR = \frac{FP}{TN +
FP} = 1 - TNR\)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>npv()</code></a></dt>
<dd>
negative predictive value, <span class="math inline">\(NPV =
\frac{TN}{TN + FN}\)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>ppr()</code></a></dt>
<dd>
positive prediction rate, <span class="math inline">\(PPR = \frac{TP +
FP}{TP + FP + TN + FN}\)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>ppv()</code></a>,
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>precision()</code></a></dt>
<dd>
positive predictive value, <span class="math inline">\(PPV =
\frac{TP}{TP + FP}\)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>pr_auc()</code></a>,
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>auc()</code></a></dt>
<dd>
area under a precision recall curve.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>roc_auc()</code></a>,
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>auc()</code></a></dt>
<dd>
<a
href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve">area
under an ROC curve</a>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>roc_index()</code></a></dt>
<dd>
a tradeoff function of sensitivity and specificity as defined by the
<code>fun</code> argument in this function (default: (sensitivity +
specificity) / 2). The function allows for specification of tradeoffs
<span class="citation">(Perkins and Schisterman 2006)</span> other than
the default of Youden’s J statistic <span class="citation">(Youden
1950)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>sensitivity()</code></a>,
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>recall()</code></a>,
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>tpr()</code></a></dt>
<dd>
true positive rate, <span class="math inline">\(TPR =\frac{TP}{TP + FN}
= 1 - FNR\)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>specificity()</code></a>,
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>tnr()</code></a></dt>
<dd>
true negative rate, <span class="math inline">\(TNR = \frac{TN}{TN + FP}
= 1 - FPR\)</span>.
</dd>
</dl>
<p>Area under the ROC and precision-recall curves as well as the
concordance index are computed directly on predicted class
probabilities. The other metrics are computed on predicted class
membership. Memberships are defined to be in the second factor level if
predicted probabilities are greater than the function default or
user-specified cutoff value.</p>
</div>
<div id="numerics" class="section level2">
<h2>Numerics</h2>
<p>Performance metrics are defined below for numeric vector responses.
If applied to a numeric matrix response, the metrics are computed
separately for each column and then averaged to produce a single
value.</p>
<dl>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>gini()</code></a></dt>
<dd>
<a href="https://en.wikipedia.org/wiki/Gini_coefficient">Gini
coefficient</a>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>mae()</code></a></dt>
<dd>
mean absolute error, <span class="math inline">\(MAE =
\frac{1}{N}\sum_{i=1}^N|y_i - \hat{y}_i|\)</span>, where <span
class="math inline">\(y_i\)</span> and <span
class="math inline">\(\hat{y}_i\)</span> are the <span
class="math inline">\(N\)</span> observed and predicted responses.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>mse()</code></a></dt>
<dd>
mean squared error, <span class="math inline">\(MSE =
\frac{1}{N}\sum_{i=1}^N(y_i - \hat{y}_i)^2\)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>msle()</code></a></dt>
<dd>
mean squared log error, <span class="math inline">\(MSLE =
\frac{1}{N}\sum_{i=1}^N(log(1 + y_i) - log(1 + \hat{y}_i))^2\)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>r2()</code></a></dt>
<dd>
one minus residual divided by total sums of squares, <span
class="math inline">\(R^2 = 1 - \sum_{i=1}^N(y_i - \hat{y}_i)^2 /
\sum_{i=1}^N(y_i - \bar{y})^2\)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>rmse()</code></a></dt>
<dd>
square root of mean squared error.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metrics"><code>rmsle()</code></a></dt>
<dd>
square root of mean squared log error.
</dd>
</dl>
</div>
<div id="survival-objects-1" class="section level2">
<h2>Survival Objects</h2>
<p>All previously described metrics for binary factor responses—plus
accuracy, Brier score and Cohen’s kappa—are applicable to survival
probabilities predicted at specified follow-up times. Metrics are
evaluated separately at each follow-up time and reported along with a
time-integrated mean. The survival concordance index is computed with
the method of Harrell <span class="citation">(1982)</span> and Brier
score according to Graf et al. <span class="citation">(1999)</span>;
whereas, the others are computed according to the confusion matrix
probabilities below, in which term <span
class="math inline">\(\hat{S}(t)\)</span> is the predicted survival
probability at follow-up time <span class="math inline">\(t\)</span> and
<span class="math inline">\(T\)</span> is the survival time <span
class="citation">(Heagerty, Lumley, and Pepe 2004)</span>.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Table 5. Confusion matrix of observed and predicted survival response
classifications.
</caption>
<thead>
<tr>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Predicted Response
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Observed Response
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Non-Event
</th>
<th style="text-align:center;">
Event
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Non-Event
</td>
<td style="text-align:center;">
<span class="math inline">\(TN = \Pr(\hat{S}(t) \ge \text{cutoff} \cap T
\gt t)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(FN = \Pr(\hat{S}(t) \ge \text{cutoff} \cap T
\le t)\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Event
</td>
<td style="text-align:center;">
<span class="math inline">\(FP = \Pr(\hat{S}(t) \lt \text{cutoff} \cap T
\gt t)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(TP = \Pr(\hat{S}(t) \lt \text{cutoff} \cap T
\le t)\)</span>
</td>
</tr>
</tbody>
</table>
<p>In addition, all of the metrics described for numeric vector
responses are applicable to predicted survival means and are computed
using only those cases with observed (non-censored) events.</p>
</div>
</div>
<div id="resampled-performance" class="section level1">
<h1>Resampled Performance</h1>
<div id="algorithms" class="section level2">
<h2>Algorithms</h2>
<p>Model performance can be estimated with resampling methods that
simulate repeated training and test set fits and predictions. With these
methods, performance metrics are computed on each resample to produce an
empirical distribution for inference. Resampling is controlled in the
<strong>MachineShop</strong> with the functions:</p>
<dl>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLControl"><code>BootControl()</code></a></dt>
<dd>
simple bootstrap resampling <span class="citation">(Efron and Tibshirani
1993)</span> to repeatedly fit a model to bootstrap resampled training
sets and predict the full dataset.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLControl"><code>BootOptimismControl()</code></a></dt>
<dd>
optimism-corrected bootstrap resampling <span class="citation">(Efron
and Gong 1983; Harrell, Lee, and Mark 1996)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLControl"><code>CVControl()</code></a></dt>
<dd>
repeated K-fold cross-validation <span class="citation">(Kohavi
1995)</span> to repeatedly partition the full dataset into K folds. For
a given partitioning, prediction is performed on each of the K folds
with models fit on all remaining folds. The package default is 10-fold
cross-validation.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLControl"><code>CVOptimismControl()</code></a></dt>
<dd>
optimism-corrected cross-validation <span class="citation">(Davison and
Hinkley 1997, eq. 6.48)</span>.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLControl"><code>OOBControl()</code></a></dt>
<dd>
out-of-bootstrap resampling to repeatedly fit a model to bootstrap
resampled training sets and predict the unsampled cases.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLControl"><code>SplitControl()</code></a></dt>
<dd>
split training and test sets <span class="citation">(Hastie, Tibshirani,
and Friedman 2009)</span> to randomly partition the full dataset for
model fitting and prediction, respectively.
</dd>
<dt><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLControl"><code>TrainControl()</code></a></dt>
<dd>
training resubstitution for both model fitting and prediction on the
full dataset in order to estimate training, or apparent, error <span
class="citation">(Efron 1986)</span>.
</dd>
</dl>
<p>For the survival example, repeated cross-validation control
structures are defined for the estimation of model performance in
predicting survival means and 5 and 10-year survival probabilities. In
addition to arguments controlling the resampling methods, a
<code>seed</code> can be set to ensure reproducibility of resampling
results obtained with the structures. The default control structure can
also be set globally by users and subsequently changed back to its
package default as desired.</p>
<pre class="r"><code>## Control structures for K-fold cross-validation

## Prediction of survival means
surv_means_control &lt;- CVControl(folds = 5, repeats = 3, seed = 123)

## Prediction of survival probabilities
surv_probs_control &lt;- CVControl(folds = 5, repeats = 3, seed = 123) %&gt;%
  set_predict(times = surv_times)

## User-specification of the default control structure
MachineShop::settings(control = CVControl(folds = 5, seed = 123))

## Package default
# MachineShop::settings(reset = &quot;control&quot;)</code></pre>
</div>
<div id="parallel-processing" class="section level2">
<h2>Parallel Processing</h2>
<p>Resampling and permutation-based variable importance are implemented
with the <strong>foreach</strong> package <span
class="citation">(Microsoft and Weston 2019)</span> and will run in
parallel if a compatible backend is loaded, such as that provided by the
<strong>doParallel</strong> <span class="citation">(Microsoft
Corporation and Weston 2019b)</span> or <strong>doSNOW</strong> package
<span class="citation">(Microsoft Corporation and Weston
2019a)</span>.</p>
<pre class="r"><code>## Register multiple cores for parallel computations
library(doParallel)
registerDoParallel(cores = 2)</code></pre>
</div>
<div id="resample-function" class="section level2">
<h2>Resample Function</h2>
<p>Resampling is performed by calling the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/resample"><code>resample()</code></a>
function with a variable specification, model, and control structure.
Like the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/fit"><code>fit()</code></a>
function, variables may be specified in terms of a traditional formula,
design matrix, model frame, or recipe.</p>
<pre class="r"><code>## Resample estimation for survival means and probabilities
(res_means &lt;- resample(surv_fo, data = surv_train, model = GBMModel,
                       control = surv_means_control))
#&gt; --- Resample object --------------------------------------------------------------------------------
#&gt; 
#&gt; Model: GBMModel
#&gt; Sampling variables:
#&gt; # A tibble: 136 × 2
#&gt;    Case  Stratification$`(strata)`
#&gt;    &lt;chr&gt; &lt;fct&gt;                    
#&gt;  1 159   0:(2.56e+03,3.45e+03]    
#&gt;  2 179   0:(3.45e+03,5.56e+03]    
#&gt;  3 14    1:[99,1.05e+03]          
#&gt;  4 195   0:(3.45e+03,5.56e+03]    
#&gt;  5 170   0:(2.56e+03,3.45e+03]    
#&gt;  6 50    0:[1.5e+03,1.92e+03]     
#&gt;  7 118   1:(1.05e+03,3.18e+03]    
#&gt;  8 43    1:(1.05e+03,3.18e+03]    
#&gt;  9 203   0:(3.45e+03,5.56e+03]    
#&gt; 10 199   0:(3.45e+03,5.56e+03]    
#&gt; # … with 126 more rows
#&gt; 
#&gt; === CVControl object ===
#&gt; 
#&gt; Label: K-Fold Cross-Validation
#&gt; Folds: 5
#&gt; Repeats: 3

(res_probs &lt;- resample(surv_fo, data = surv_train, model = GBMModel,
                       control = surv_probs_control))
#&gt; --- Resample object --------------------------------------------------------------------------------
#&gt; 
#&gt; Model: GBMModel
#&gt; Sampling variables:
#&gt; # A tibble: 136 × 2
#&gt;    Case  Stratification$`(strata)`
#&gt;    &lt;chr&gt; &lt;fct&gt;                    
#&gt;  1 159   0:(2.56e+03,3.45e+03]    
#&gt;  2 179   0:(3.45e+03,5.56e+03]    
#&gt;  3 14    1:[99,1.05e+03]          
#&gt;  4 195   0:(3.45e+03,5.56e+03]    
#&gt;  5 170   0:(2.56e+03,3.45e+03]    
#&gt;  6 50    0:[1.5e+03,1.92e+03]     
#&gt;  7 118   1:(1.05e+03,3.18e+03]    
#&gt;  8 43    1:(1.05e+03,3.18e+03]    
#&gt;  9 203   0:(3.45e+03,5.56e+03]    
#&gt; 10 199   0:(3.45e+03,5.56e+03]    
#&gt; # … with 126 more rows
#&gt; 
#&gt; === CVControl object ===
#&gt; 
#&gt; Label: K-Fold Cross-Validation
#&gt; Folds: 5
#&gt; Repeats: 3</code></pre>
</div>
<div id="summary-statistics" class="section level2">
<h2>Summary Statistics</h2>
<p>The <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/summary"><code>summary()</code></a>
function when applied directly to output from <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/resample"><code>resample()</code></a>
computes summary statistics for the default performance metrics
described in the <em>Performance Function</em> section.</p>
<pre class="r"><code>## Summary of survival means metric
summary(res_means)
#&gt;          Statistic
#&gt; Metric         Mean   Median         SD       Min       Max NA
#&gt;   C-Index 0.7463392 0.760181 0.05087334 0.6497797 0.8160377  0

## Summary of survival probability metrics
summary(res_probs)
#&gt;                 Statistic
#&gt; Metric                Mean    Median         SD       Min       Max NA
#&gt;   Brier.Mean     0.1840798 0.1656891 0.04219018 0.1384248 0.2799741  0
#&gt;   Brier.Time1    0.1689041 0.1700111 0.02573429 0.1146578 0.2094401  0
#&gt;   Brier.Time2    0.1992555 0.1646532 0.07325704 0.1107217 0.3505637  0
#&gt;   ROC AUC.Mean   0.7923960 0.8100544 0.07409293 0.6498228 0.9059051  0
#&gt;   ROC AUC.Time1  0.7968504 0.8109520 0.06961892 0.6698605 0.8881988  0
#&gt;   ROC AUC.Time2  0.7879415 0.8124010 0.08943567 0.6203522 0.9438344  0
#&gt;   Accuracy.Mean  0.7375050 0.7279678 0.05497218 0.6556134 0.8265224  0
#&gt;   Accuracy.Time1 0.7656228 0.7650000 0.06670304 0.6607143 0.9000000  0
#&gt;   Accuracy.Time2 0.7093872 0.7002405 0.07197984 0.6101648 0.8717949  0</code></pre>
<p>Other relevant metrics can be identified with <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/metricinfo"><code>metricinfo()</code></a>
and summarized with <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/performance"><code>performance()</code></a>.</p>
<pre class="r"><code>## Resample-specific metrics
metricinfo(res_means) %&gt;% names
#&gt; [1] &quot;cindex&quot; &quot;gini&quot;   &quot;mae&quot;    &quot;mse&quot;    &quot;msle&quot;   &quot;r2&quot;     &quot;rmse&quot;   &quot;rmsle&quot;

## User-specified survival means metrics
summary(performance(res_means, metrics = c(cindex, rmse)))
#&gt;         Statistic
#&gt; Metric           Mean      Median           SD          Min          Max NA
#&gt;   cindex    0.7463392    0.760181 5.087334e-02    0.6497797    0.8160377  0
#&gt;   rmse   3919.1261727 3535.514283 1.454999e+03 2373.4128247 7558.2801759  0</code></pre>
<p>Furthermore, summaries can be customized with a user-defined
statistics function or list of statistics functions passed to the
<code>stats</code> argument of <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/summary"><code>summary()</code></a>.</p>
<pre class="r"><code>## User-defined statistics function
percentiles &lt;- function(x) quantile(x, probs = c(0.25, 0.50, 0.75))
summary(res_means, stats = percentiles)
#&gt;          Statistic
#&gt; Metric          25%      50%       75% NA
#&gt;   C-Index 0.7196886 0.760181 0.7770528  0

## User-defined list of statistics functions
summary(res_means, stats = c(Mean = mean, Percentile = percentiles))
#&gt;          Statistic
#&gt; Metric         Mean Percentile.25% Percentile.50% Percentile.75% NA
#&gt;   C-Index 0.7463392      0.7196886       0.760181      0.7770528  0</code></pre>
</div>
<div id="plots" class="section level2">
<h2>Plots</h2>
<p>Summary plots of resample output can be obtained with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/plot"><code>plot()</code></a>
function. Boxplots are the default plot type; but density, errorbar, and
violin plots are also available. Plots are generated with the
<strong>ggplot2</strong> package <span class="citation">(Wickham
2016)</span> and returned as <code>ggplot</code> objects. As such,
annotation and formatting defined for ggplots can be applied to the
returned plots.</p>
<pre class="r"><code>## Libraries for plot annotation and fomatting
library(ggplot2)
library(gridExtra)

## Individual ggplots
p1 &lt;- plot(res_means)
p2 &lt;- plot(res_means, type = &quot;density&quot;)
p3 &lt;- plot(res_means, type = &quot;errorbar&quot;)
p4 &lt;- plot(res_means, type = &quot;violin&quot;)

## Grid of plots
grid.arrange(p1, p2, p3, p4, nrow = 2)</code></pre>
<p><img src="using_files/figure-html/using_resample_plots-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="stratified-resampling" class="section level2">
<h2>Stratified Resampling</h2>
<p>Stratification of cases for the construction of resampled training
and test sets can be employed to help achieve balance across the sets.
Stratified resampling is automatically performed if variable
specification is in terms of a traditional formula or design matrix and
will be done according to the response variable. For model frames and
recipes, stratification variables must be defined explicitly with the
<code>strata</code> argument to the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelFrame"><code>ModelFrame()</code></a>
constructor or with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/recipe_roles"><code>role_case()</code></a>
function. In general, strata are constructed from numeric proportions
for <code>BinomialVariate</code>; original values for
<code>character</code>, <code>factor</code>, <code>logical</code>, and
<code>ordered</code>; first columns of values for <code>matrix</code>;
original values for <code>numeric</code>; and numeric times within event
statuses for <code>Surv</code>. Numeric values are stratified into
quantile bins and categorical values into factor levels defined by the
resampling control functions. Missing values are replaced with
non-missing values sampled at random with replacement.</p>
<pre class="r"><code>## Model frame with response variable stratification
mf &lt;- ModelFrame(surv_fo, data = surv_train, strata = surv_train$y)
resample(mf, model = GBMModel)

## Recipe with response variable stratification
rec &lt;- recipe(y ~ ., data = surv_train) %&gt;%
  role_case(stratum = y)
resample(rec, model = GBMModel)</code></pre>
</div>
<div id="dynamic-model-parameters-1" class="section level2">
<h2>Dynamic Model Parameters</h2>
<p>As discussed previously in the <em>Model Fit and Prediction</em>
section, dynamic model parameters are evaluated at the time of model
fitting and can depend on the number of observations in the fitted
dataset. In the context of resampling, dynamic parameters are repeatedly
evaluated at each fit of the resampled datasets. As such, their values
can change based on the observations selected for training at each
iteration of the resampling algorithm.</p>
<pre class="r"><code>## Dynamic model parameter k = log number of training set observations
resample(surv_fo, data = surv_train, model = CoxStepAICModel(k = .(log(nobs))))</code></pre>
</div>
<div id="model-comparisons" class="section level2">
<h2>Model Comparisons</h2>
<p>Resampled metrics from different models can be combined for
comparison with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/combine"><code>c()</code></a>
function. Optional names given on the left hand side of equal operators
within <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/combine"><code>c()</code></a>
calls will be used as labels in output from the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/summary"><code>summary()</code></a>
and <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/plot"><code>plot()</code></a>
functions. For comparisons of resampled output, the same control
structure must be used in all associated calls to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/resample"><code>resample()</code></a>
to ensure that resulting model metrics are computed on the same
resampled training and test sets. The combined resample output can be
summarized and plotted as usual.</p>
<pre class="r"><code>## Resample estimation
res1 &lt;- resample(surv_fo, data = surv_train, model = GBMModel(n.trees = 25),
                 control = surv_means_control)
res2 &lt;- resample(surv_fo, data = surv_train, model = GBMModel(n.trees = 50),
                 control = surv_means_control)
res3 &lt;- resample(surv_fo, data = surv_train, model = GBMModel(n.trees = 100),
                 control = surv_means_control)

## Combine resample output for comparison
(res &lt;- c(GBM1 = res1, GBM2 = res2, GBM3 = res3))
#&gt; --- Resample object --------------------------------------------------------------------------------
#&gt; 
#&gt; Models: GBM1, GBM2, GBM3
#&gt; Sampling variables:
#&gt; # A tibble: 136 × 2
#&gt;    Case  Stratification$`(strata)`
#&gt;    &lt;chr&gt; &lt;fct&gt;                    
#&gt;  1 159   0:(2.56e+03,3.45e+03]    
#&gt;  2 179   0:(3.45e+03,5.56e+03]    
#&gt;  3 14    1:[99,1.05e+03]          
#&gt;  4 195   0:(3.45e+03,5.56e+03]    
#&gt;  5 170   0:(2.56e+03,3.45e+03]    
#&gt;  6 50    0:[1.5e+03,1.92e+03]     
#&gt;  7 118   1:(1.05e+03,3.18e+03]    
#&gt;  8 43    1:(1.05e+03,3.18e+03]    
#&gt;  9 203   0:(3.45e+03,5.56e+03]    
#&gt; 10 199   0:(3.45e+03,5.56e+03]    
#&gt; # … with 126 more rows
#&gt; 
#&gt; === CVControl object ===
#&gt; 
#&gt; Label: K-Fold Cross-Validation
#&gt; Folds: 5
#&gt; Repeats: 3

summary(res)
#&gt; , , Metric = C-Index
#&gt; 
#&gt;       Statistic
#&gt; Model       Mean    Median         SD       Min       Max NA
#&gt;   GBM1 0.7748099 0.7951389 0.04746402 0.6497797 0.8301887  0
#&gt;   GBM2 0.7647633 0.7630332 0.05151443 0.6497797 0.8632075  0
#&gt;   GBM3 0.7463392 0.7601810 0.05087334 0.6497797 0.8160377  0

plot(res)</code></pre>
<p><img src="using_files/figure-html/using_resample_comparisons-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Pairwise model differences for each metric can be calculated with the
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/diff"><code>diff()</code></a>
function applied to results from a call to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/combine"><code>c()</code></a>.
Resulting differences can be summarized descriptively with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/summary"><code>summary()</code></a>
and <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/plot"><code>plot()</code></a>
functions and assessed for statistical significance with pairwise
t-tests performed by the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/t.test"><code>t.test()</code></a>
function. The t-test statistic for a given set of <span
class="math inline">\(R\)</span> resampled differences is calculated as
<span class="math display">\[
t = \frac{\bar{x}_R}{\sqrt{F s^2_R / R}},
\]</span> where <span class="math inline">\(\bar{x}_R\)</span> and <span
class="math inline">\(s^2_R\)</span> are the sample mean and variance.
Statistical testing for a mean difference is then performed by comparing
<span class="math inline">\(t\)</span> to a <span
class="math inline">\(t_{R-1}\)</span> null distribution. The sample
variance in the t statistic is known to underestimate the true variances
of cross-validation mean estimators. Underestimation of these variances
will lead to increased probabilities of false-positive statistical
conclusions. Thus, an additional factor <span
class="math inline">\(F\)</span> is included in the t statistic to allow
for variance corrections. A correction of <span class="math inline">\(F
= 1 + K / (K - 1)\)</span> was found by Nadeau and Bengio <span
class="citation">(2003)</span> to be a good choice for cross-validation
with <span class="math inline">\(K\)</span> folds and is thus used for
that resampling method. The extension of this correction by Bouchaert
and Frank <span class="citation">(2004)</span> to <span
class="math inline">\(F = 1 + T K / (K - 1)\)</span> is used for
cross-validation with <span class="math inline">\(K\)</span> folds
repeated <span class="math inline">\(T\)</span> times. For other
resampling methods <span class="math inline">\(F = 1\)</span>. Below are
t-test results based on the extended correction factor for 3 repeats of
5-fold cross-validation.</p>
<pre class="r"><code>## Pairwise model comparisons
(res_diff &lt;- diff(res))
#&gt; --- PerformanceDiff object -------------------------------------------------------------------------
#&gt; 
#&gt; Metric: C-Index
#&gt; Models: GBM1 - GBM2, GBM1 - GBM3, GBM2 - GBM3
#&gt; 
#&gt; === CVControl object ===
#&gt; 
#&gt; Label: K-Fold Cross-Validation
#&gt; Folds: 5
#&gt; Repeats: 3

summary(res_diff)
#&gt; , , Metric = C-Index
#&gt; 
#&gt;              Statistic
#&gt; Model               Mean     Median         SD          Min        Max NA
#&gt;   GBM1 - GBM2 0.01004663 0.01388889 0.02165165 -0.033018868 0.03973510  0
#&gt;   GBM1 - GBM3 0.02847075 0.02903226 0.02584321 -0.009803922 0.08293839  0
#&gt;   GBM2 - GBM3 0.01842412 0.01376147 0.01974621  0.000000000 0.05743243  0

plot(res_diff)</code></pre>
<p><img src="using_files/figure-html/using_resample_diff-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>t.test(res_diff)
#&gt; --- PerformanceDiffTest object ---------------------------------------------------------------------
#&gt; 
#&gt; Upper diagonal: mean differences (Model1 - Model2)
#&gt; Lower diagonal: p-values
#&gt; P-value adjustment method: holm
#&gt; 
#&gt; , , Metric = C-Index
#&gt; 
#&gt;       Model2
#&gt; Model1      GBM1       GBM2       GBM3
#&gt;   GBM1        NA 0.01004663 0.02847075
#&gt;   GBM2 0.4234417         NA 0.01842412
#&gt;   GBM3 0.2115012 0.23906539         NA</code></pre>
</div>
</div>
<div id="model-predictor-effects-and-diagnostics"
class="section level1">
<h1>Model Predictor Effects and Diagnostics</h1>
<p>Calculation of performance metrics on test sets or by resampling, as
discussed previously, is one method of assessing model performance.
Others available include measures of predictor variable importance,
partial dependence plots, calibration curves comparing observed and
predicted response values, and receiver operating characteristic
analysis.</p>
<div id="variable-importance" class="section level2">
<h2>Variable Importance</h2>
<p>The importance of predictor variables in a model fit is estimated
with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/varimp"><code>varimp()</code></a>
function and displayed graphically with <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/plot"><code>plot()</code></a>.
Variable importance is a relative measure of the contributions of model
predictors and is scaled by default to have a maximum value of 100,
where higher values represent more important variables. Model-specific
implementations of variable importance are available in many cases,
although their definitions may differ. In the case of a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>,
importance of each predictor is based on the sum of squared empirical
improvements over all internal tree nodes created by splitting on that
variable <span class="citation">(Greenwell et al. 2019)</span>.</p>
<pre class="r"><code>## Predictor variable importance
(vi &lt;- varimp(surv_fit, method = &quot;model&quot;))
#&gt; --- VariableImportance object ----------------------------------------------------------------------
#&gt;             Overall
#&gt; age       100.00000
#&gt; thickness  78.27486
#&gt; year       45.60724
#&gt; ulcer      26.88075
#&gt; sex         8.93267

plot(vi)</code></pre>
<p><img src="using_files/figure-html/using_analyses_vi-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>In contrast, importance is based on negative log-transformed p-values
for statistical models, like <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/CoxModel"><code>CoxModel</code></a>,
that produce them. For other models, variable importance may be defined
and calculated by their underlying source packages or not defined at
all, as is the case for <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SVMModel"><code>SVMModel</code></a>.
Logical indicators of model-specific variable importance are given in
the information displayed by model constructors and returned by <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/modelinfo"><code>modelinfo()</code></a>.</p>
<pre class="r"><code>SVMModel
#&gt; --- MLModelFunction object -------------------------------------------------------------------------
#&gt; 
#&gt; Model name: SVMModel
#&gt; Label: Support Vector Machines
#&gt; Package: kernlab
#&gt; Response types: factor, numeric
#&gt; Case weights support: FALSE
#&gt; Missing case removal: all
#&gt; Tuning grid: FALSE
#&gt; Variable importance: FALSE
#&gt; 
#&gt; Arguments:
#&gt; function (scaled = TRUE, type = character(), kernel = c(&quot;rbfdot&quot;, 
#&gt;     &quot;polydot&quot;, &quot;vanilladot&quot;, &quot;tanhdot&quot;, &quot;laplacedot&quot;, &quot;besseldot&quot;, 
#&gt;     &quot;anovadot&quot;, &quot;splinedot&quot;), kpar = &quot;automatic&quot;, C = 1, nu = 0.2, 
#&gt;     epsilon = 0.1, prob.model = FALSE, cache = 40, tol = 0.001, 
#&gt;     shrinking = TRUE) 
#&gt; NULL

modelinfo(SVMModel)[[1]]$varimp
#&gt; [1] FALSE</code></pre>
<p>Variable importance can be computed with model-agnostic permutation
methods <span class="citation">(Fisher, Rudin, and Dominici 2019)</span>
as an alternative to model-specific methods. The following algorithm for
permutation-based variable importance is implemented and the default
method in <strong>MachineShop</strong>.</p>
<ul>
<li><p>Fit a model to a training dataset.</p></li>
<li><p>Compute training performance.</p></li>
<li><p>For <span class="math inline">\(s = 1, \ldots, S\)</span>.</p>
<ul>
<li><p>Optionally sample a subset of the training set without
replacement.</p></li>
<li><p>For predictor variable <span class="math inline">\(p = 1, \ldots,
P\)</span>.</p>
<ul>
<li><p>Randomly permute the variable values.</p></li>
<li><p>Compute performance on the permutation set.</p></li>
<li><p>Compute importance as the difference or ratio between the
permutation and training performances.</p></li>
<li><p>Reset the variable to its original values.</p></li>
</ul></li>
</ul></li>
<li><p>Return the mean or other summary statistics of importance for
each variable.</p></li>
</ul>
<pre class="r"><code>## Permutation-based variable importance
varimp(surv_fit)
#&gt; --- VariableImportance object ----------------------------------------------------------------------
#&gt;           Permute.mean.cindex
#&gt; age                100.000000
#&gt; thickness           90.837696
#&gt; ulcer               69.371728
#&gt; year                50.130890
#&gt; sex                  6.151832</code></pre>
<p>There are a number of advantages to permutation-based variable
importance. In particular, it can be computed for any</p>
<ol style="list-style-type: decimal">
<li>model,</li>
<li>performance metric defined for the given response variable type,
and</li>
<li>predictor variable in the original training set.</li>
</ol>
<p>Conversely, model-specific methods are not defined for some models,
are generally limited to metrics implemented in their source packages,
and might be computed on derived, rather than original, predictor
variables. These differences can make comparisons of variable importance
across classes of models difficult if not impossible. The trade-off for
the advantages of a permutation-based approach is increased computation
time. To speed up computations, the algorithm will run in parallel if a
compatible backend is loaded as described in the <em>Parallel
Processing</em> section.</p>
</div>
<div id="recursive-feature-elimination" class="section level2">
<h2>Recursive Feature Elimination</h2>
<p>Recursive feature elimination (RFE) is a wrapper method of variable
selection. In wrapper methods, a given model is fit to subsets of
predictor variables in order to select the subset whose fit is optimal.
Forward, backward, and step-wise variable selection are examples of
wrapper methods. RFE is a type of backward selection in which subsets
are formed from decreasing numbers of the most important predictor
variables. The RFE algorithm implemented in the package-supplied
<code>rfe()</code> function is summarized below.</p>
<ul>
<li><p>Compute variable importance for all predictors.</p></li>
<li><p>For predictor subsets of sizes <span class="math inline">\(S =
S_n &gt; ... &gt; S_1\)</span>.</p>
<ul>
<li><p>Eliminate predictors whose variable importance is not in the top
<span class="math inline">\(S\)</span> by randomly permuting their
values.</p></li>
<li><p>Compute a resampled estimate of model predictive
performance.</p></li>
<li><p>Optionally recompute variable importance for the top <span
class="math inline">\(S\)</span> predictors, and set importance equal to
zero for those eliminated.</p></li>
</ul></li>
<li><p>Select the predictor set with highest predictive
performance.</p></li>
</ul>
<p>This RFE algorithm differs from others in that variables are
“eliminated” by permuting their values rather than by removing them from
the dataset. Using a permutation approach for both the elimination of
variables and computation of variable importance enables application of
the <code>rfe()</code> function to any variable specification
(traditional formula, design matrix, model frame, or recipe) and any
model available in the package. The syntax for <code>rfe()</code> is
similar to <code>resample()</code> as illustrated in the following
example.</p>
<pre class="r"><code>## Recursive feature elimination
(surv_rfe &lt;- rfe(surv_fo, data = surv_train, model = GBMModel,
                 control = surv_means_control))
#&gt; --- TrainingStep object ----------------------------------------------------------------------------
#&gt; 
#&gt; Optimization method: Global Recursive Feature Elimination
#&gt; ModelSpecification log:
#&gt; # A tibble: 4 × 5
#&gt;   name                 terms     selected params$size metrics$`C-Index`
#&gt;   &lt;chr&gt;                &lt;list&gt;    &lt;lgl&gt;          &lt;int&gt;             &lt;dbl&gt;
#&gt; 1 ModelSpecification.1 &lt;chr [5]&gt; FALSE              5             0.746
#&gt; 2 ModelSpecification.2 &lt;chr [4]&gt; FALSE              4             0.736
#&gt; 3 ModelSpecification.3 &lt;chr [2]&gt; TRUE               2             0.748
#&gt; 4 ModelSpecification.4 &lt;chr [1]&gt; FALSE              1             0.701
#&gt; 
#&gt; Selected row: 3
#&gt; Metric: C-Index = 0.7481588
rfe_summary &lt;- summary(surv_rfe)
rfe_summary$terms[rfe_summary$selected]
#&gt; [[1]]
#&gt; [1] &quot;age&quot;       &quot;thickness&quot;</code></pre>
</div>
<div id="partial-dependence-plots" class="section level2">
<h2>Partial Dependence Plots</h2>
<p>Partial dependence plots show the marginal effects of predictors on a
response variable. Dependence for a select set of one or more predictor
variables <span class="math inline">\(X_S\)</span> is computed as <span
class="math display">\[
\bar{f}_S(X_S) = \frac{1}{N}\sum_{i=1}^N f(X_S, x_{iS&#39;}),
\]</span> where <span class="math inline">\(f\)</span> is a fitted
prediction function and <span class="math inline">\(x_{iS&#39;}\)</span>
are values of the remaining predictors in a dataset of <span
class="math inline">\(N\)</span> cases. The response scale displayed in
dependence plots will depend on the response variable type: probability
for predicted factors and survival probabilities, original scale for
numerics, and survival time for predicted survival means. By default,
dependence is computed for each selected predictor individually over a
grid of 10 approximately evenly spaced values and averaged over the
dataset on which the prediction function was fit.</p>
<pre class="r"><code>## Partial dependence plots
pd &lt;- dependence(surv_fit, select = c(thickness, age))
plot(pd)</code></pre>
<p><img src="using_files/figure-html/using_analyses_pd-1.png" width="672" style="display: block; margin: auto;" /><img src="using_files/figure-html/using_analyses_pd-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>Estimated predictor effects are marginal in that they are averaged
over the remaining variables, whose distribution depends on the
population represented by the dataset. Consequently, partial dependence
plots for a given model can vary across datasets and populations. The
package allows averaging over different datasets to estimate marginal
effects in other case populations, over different numbers of predictor
values, and over quantile spacing of the values.</p>
<pre class="r"><code>pd &lt;- dependence(surv_fit, data = surv_test, select = thickness, n = 20,
                 intervals = &quot;quantile&quot;)
plot(pd)</code></pre>
<p><img src="using_files/figure-html/using_analyses_pd_data-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>In addition, dependence may be computed for combinations of multiple
predictors to examine interaction effects and for summary statistics
other than the mean.</p>
</div>
<div id="calibration-curves" class="section level2">
<h2>Calibration Curves</h2>
<p>Agreement between model-predicted and observed values can be
visualized with calibration curves. Calibration curves supplement
individual performance metrics with information on model fit in
different regions of predicted values. They also provide more direct
assessment of agreement than some performance metrics, like ROC AUC,
that do not account for scale and location differences. In the
construction of binned calibration curves, cases are partitioned into
equal-width intervals according to their (resampled) predicted
responses. Mean observed responses are then calculated within each of
the bins and plotted on the vertical axis against the bin midpoints on
the horizontal axis.</p>
<pre class="r"><code>## Binned calibration curves
cal &lt;- calibration(res_probs, breaks = 10)
plot(cal, se = TRUE)</code></pre>
<p><img src="using_files/figure-html/using_analyses_cal-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>As an alternative to discrete bins, curves can be smoothed by setting
<code>breaks = NULL</code> to compute weighted averages of observed
values. Smoothing has the advantage of producing more precise curves by
including more observed values in the calculation at each predicted
value.</p>
<pre class="r"><code>## Smoothed calibration curves
cal &lt;- calibration(res_probs, breaks = NULL)
plot(cal)</code></pre>
<p><img src="using_files/figure-html/using_analyses_cal_smoothed-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Calibration curves close to the 45<span
class="math inline">\(^\circ\)</span> line represent agreement between
observed and predicted responses and a model that is said to be well
calibrated.</p>
</div>
<div id="confusion-matrices" class="section level2">
<h2>Confusion Matrices</h2>
<p>Confusion matrices of cross-classified observed and predicted
categorical responses are available with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/confusion"><code>confusion()</code></a>
function. They can be constructed with predicted class membership or
with predicted class probabilities. In the latter case, predicted class
membership is derived from predicted probabilities according to a
probability cutoff value for binary factors (default:
<code>cutoff = 0.5</code>) and according to the class with highest
probability for factors with more than two levels.</p>
<pre class="r"><code>## Confusion matrices
(conf &lt;- confusion(res_probs, cutoff = 0.7))
#&gt; --- ConfusionList object ---------------------------------------------------------------------------
#&gt; 
#&gt; === $GBMModel.Time1 ================================================================================
#&gt; === BinaryConfusionMatrix object ===
#&gt;          Observed
#&gt; Predicted         0         1
#&gt;         0 236.02496  38.97504
#&gt;         1  59.34328  73.65672
#&gt; 
#&gt; === $GBMModel.Time2 ================================================================================
#&gt; === BinaryConfusionMatrix object ===
#&gt;          Observed
#&gt; Predicted         0         1
#&gt;         0 170.20031  34.79969
#&gt;         1  82.12352 120.87648</code></pre>
<pre class="r"><code>plot(conf)</code></pre>
<p><img src="using_files/figure-html/using_analyses_conf_plot-1.png" width="672" style="display: block; margin: auto;" /><img src="using_files/figure-html/using_analyses_conf_plot-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>Confusion matrices are the data structure upon which many of the
performance metrics described earlier for factor predictor variables are
based. Metrics commonly reported for confusion matrices are generated by
the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/summary"><code>summary()</code></a>
function.</p>
<pre class="r"><code>## Summary performance metrics
summary(conf)
#&gt; --- $GBMModel.Time1 --------------------------------------------------------------------------------
#&gt; Number of responses: 408
#&gt; Accuracy (SE): 0.7590237 (0.02117311)
#&gt; Majority class: 0.7239418
#&gt; Kappa: 0.4290466
#&gt; 
#&gt;                     0         1
#&gt; Observed    0.7239418 0.2760582
#&gt; Predicted   0.6740196 0.3259804
#&gt; Agreement   0.5784925 0.1805312
#&gt; Sensitivity 0.7990871 0.6539605
#&gt; Specificity 0.6539605 0.7990871
#&gt; PPV         0.8582726 0.5538099
#&gt; NPV         0.5538099 0.8582726
#&gt; 
#&gt; --- $GBMModel.Time2 --------------------------------------------------------------------------------
#&gt; Number of responses: 408
#&gt; Accuracy (SE): 0.7134235 (0.02238535)
#&gt; Majority class: 0.6184408
#&gt; Kappa: 0.4261807
#&gt; 
#&gt;                     0         1
#&gt; Observed    0.6184408 0.3815592
#&gt; Predicted   0.5024510 0.4975490
#&gt; Agreement   0.4171576 0.2962659
#&gt; Sensitivity 0.6745312 0.7764610
#&gt; Specificity 0.7764610 0.6745312
#&gt; PPV         0.8302454 0.5954506
#&gt; NPV         0.5954506 0.8302454</code></pre>
<p>Summaries can also be obtained with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/performance"><code>performance()</code></a>
function for default or use-specified metrics.</p>
<pre class="r"><code>## Confusion matrix-specific metrics
metricinfo(conf) %&gt;% names
#&gt;  [1] &quot;accuracy&quot;    &quot;f_score&quot;     &quot;fnr&quot;         &quot;fpr&quot;         &quot;kappa2&quot;     
#&gt;  [6] &quot;npv&quot;         &quot;ppr&quot;         &quot;ppv&quot;         &quot;precision&quot;   &quot;recall&quot;     
#&gt; [11] &quot;roc_index&quot;   &quot;sensitivity&quot; &quot;specificity&quot; &quot;tnr&quot;         &quot;tpr&quot;

## User-specified metrics
performance(conf, metrics = c(&quot;Accuracy&quot; = accuracy,
                              &quot;Sensitivity&quot; = sensitivity,
                              &quot;Specificity&quot; = specificity))
#&gt; --- $GBMModel.Time1 --------------------------------------------------------------------------------
#&gt;    Accuracy Sensitivity Specificity 
#&gt;   0.7590237   0.6539605   0.7990871 
#&gt; 
#&gt; --- $GBMModel.Time2 --------------------------------------------------------------------------------
#&gt;    Accuracy Sensitivity Specificity 
#&gt;   0.7134235   0.7764610   0.6745312</code></pre>
</div>
<div id="performance-curves" class="section level2">
<h2>Performance Curves</h2>
<p>Tradeoffs between correct and incorrect classifications of binary
responses, across the range of possible cutoff probabilities, can be
studied with performance curves. In general, any two binary response
metrics may be specified for the construction of a performance
curve.</p>
<div id="roc-curves" class="section level3">
<h3>ROC Curves</h3>
<p>Receiver operating characteristic (ROC) curves are one example in
which true positive rates (sensitivity) are plotted against false
positive rates (1 - specificity) <span class="citation">(Fawcett
2006)</span>. True positive rate (TPR) and false positive rate (FPR) are
defined as <span class="math display">\[
\begin{aligned}
TPR &amp;= \text{sensitivity} = \Pr(\hat{p} &gt; c \mid D^+) \\
FPR &amp;= 1 - \text{specificity} = \Pr(\hat{p} &gt; c \mid D^-),
\end{aligned}
\]</span> where <span class="math inline">\(\hat{p}\)</span> is the
model-predicted probability of being positive, <span
class="math inline">\(0 \le c \le 1\)</span> is a probability cutoff
value for classification as positive or negative, and <span
class="math inline">\(D^+/D^-\)</span> is positive/negative case status.
ROC curves show tradeoffs between the two rates over the range of
possible cutoff values. Higher curves are indicative of better
predictive performance.</p>
<pre class="r"><code>## ROC curves
roc &lt;- performance_curve(res_probs)
plot(roc, diagonal = TRUE)</code></pre>
<p><img src="using_files/figure-html/using_analyses_roc-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>ROC curves show the relation between the two rates being plotted but
not their relationships with specific cutoff values. The latter may be
helpful for the selection of a cutoff to apply in practice. Accordingly,
separate plots of each rate versus the range of possible cutoffs are
available with the <code>type = "cutoffs"</code> option.</p>
<pre class="r"><code>plot(roc, type = &quot;cutoffs&quot;)</code></pre>
<p><img src="using_files/figure-html/using_analyses_roc_cutoffs-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Area under the ROC curve (ROC AUC) is an overall measure of model
predictive performance. It is interpreted as the probability that a
randomly selected positive case will have a higher predicted value than
a randomly selected negative case. AUC values of 0.5 and 1.0 indicate
chance and perfect <em>concordance</em> between predicted probabilities
and observed responses.</p>
<pre class="r"><code>auc(roc)
#&gt; Model: GBMModel.Time1
#&gt; [1] 0.7966402
#&gt; ------------------------------------------------------------ 
#&gt; Model: GBMModel.Time2
#&gt; [1] 0.7818386</code></pre>
</div>
<div id="precision-recall-curves" class="section level3">
<h3>Precision Recall Curves</h3>
<p>Precision recall curves plot precision (positive predictive value)
against recall (sensitivity) <span class="citation">(Davis and Goadrich
2006)</span>, where <span class="math display">\[
\begin{aligned}
  \text{precision} &amp;= PPV = \Pr(D^+ \mid \hat{p} &gt; c) \\
  \text{recall} &amp;= \text{sensitivity} = \Pr(\hat{p} &gt; c \mid
D^+).
\end{aligned}
\]</span> These curves tend to be used when primary interest lies in
detecting positive cases and such cases are rare.</p>
<pre class="r"><code>## Precision recall curves
pr &lt;- performance_curve(res_probs, metrics = c(precision, recall))
plot(pr)</code></pre>
<p><img src="using_files/figure-html/using_analyses_pr-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>auc(pr)
#&gt; Model: GBMModel.Time1
#&gt; [1] 0.562425
#&gt; ------------------------------------------------------------ 
#&gt; Model: GBMModel.Time2
#&gt; [1] 0.6359023</code></pre>
</div>
<div id="lift-curves" class="section level3">
<h3>Lift Curves</h3>
<p>Lift curves depict the rate at which positive cases are found as a
function of the proportion predicted to be positive in the population.
In particular, they plot true positive rate (sensitivity) against
positive prediction rate (PPR) for all possible classification
probability cutoffs, where <span class="math display">\[
\begin{aligned}
  TPR &amp;= \Pr(\hat{p} &gt; c \mid D^+) \\
  PPR &amp;= \Pr(\hat{p} &gt; c).
\end{aligned}
\]</span> Models more efficient (lower cost) at identifying positive
cases find them at a higher proportion (<span
class="math inline">\(TPR\)</span>) while predicting fewer in the
overall population to be positive (<span
class="math inline">\(PPR\)</span>). In other words, higher lift curves
are signs of model efficiency.</p>
<pre class="r"><code>## Lift curves
lf &lt;- lift(res_probs)
plot(lf, find = 0.75)</code></pre>
<p><img src="using_files/figure-html/using_analyses_lift-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="modeling-strategies" class="section level1">
<h1>Modeling Strategies</h1>
<p>Model development often involves the comparison of multiple models
from a candidate set for the purpose of selecting a final one. Models in
the set may differ with respect to their predictor variables,
preprocessing steps and parameters, and model types and parameters.
Complex model selection strategies for sets that involve one or more of
these differences can be implemented with the
<strong>MachineShop</strong> package. Implementation is achieved with a
straightforward syntax based on the meta-input and meta-model functions
listed in the table below and with resampling, including nested
resampling, conducted automatically for model selection and predictive
performance evaluation.</p>
<table>
<colgroup>
<col width="31%" />
<col width="35%" />
<col width="32%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Parameter Grid Tuning</th>
<th align="left">Candidate Set Selection</th>
<th align="left">Ensemble Learning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedInput"><code>TunedInput()</code></a></td>
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedInput"><code>SelectedInput()</code></a></td>
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/StackedModel"><code>StackedModel()</code></a></td>
</tr>
<tr class="even">
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedModel"><code>TunedModel()</code></a></td>
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedModel"><code>SelectedModel()</code></a></td>
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SuperModel"><code>SuperModel()</code></a></td>
</tr>
</tbody>
</table>
<p>These meta-functions fall into three main categories: 1) tuning of a
given input or model over a grid of parameter values, 2) selection from
an arbitrary set of different inputs or models, or 3) combining multiple
models into an ensemble learner. In the context of these strategies, an
input may be a formula, design matrix, model frame, or preprocessing
recipe. The meta-input and meta-model functions themselves return input
and model class objects, respectively. Combinations and multiple levels
of nesting of meta-functions, inputs, and models are allowed. For
example, <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/StackedModel"><code>StackedModel()</code></a>
and <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SuperModel"><code>SuperModel()</code></a>
may consist of <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedModel"><code>TunedModel</code></a>
and other model objects. <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedModel"><code>SelectedModel()</code></a>
can select among mixes of <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedModel"><code>TunedModel</code></a>,
ensemble model, and other model objects. Likewise, <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedInput"><code>TunedInput</code></a>
objects, along with other inputs, may be nested within <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedInput"><code>SelectedInput()</code></a>.
Furthermore, selection and tuning of both inputs and models can be
performed simultaneously. These and other possibilities are illustrated
in the following sections.</p>
<div id="inputs" class="section level2">
<h2>Inputs</h2>
<p>Inputs to model fitting functions define the predictor and response
variables and the dataset containing their values. These can be
specified with traditional formula and dataset pairs, design matrix and
response variable pairs, model frames, and preprocessing recipes. The
package supports (1) tuning of an input over a grid of parameter values
and (2) selection of inputs from candidate sets that differ with respect
to their predictors or their preprocessing steps and parameters.</p>
<div id="input-tuning" class="section level3">
<h3>Input Tuning</h3>
<p>Preprocessing recipes may have step with parameters that affect
predictive performance. Steps can be tuned over a grid of parameter
values with <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedInput"><code>TunedInput()</code></a>
to select the best performing values. Calls to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedInput"><code>TunedInput()</code></a>
return an input object that may be trained on data with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/fit"><code>fit()</code></a>
function or evaluated for predictive performance with <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/resample"><code>resample()</code></a>.
As an example, a principal components analysis (PCA) step could be
included in a preprocessing recipe for tuning over the number of
components to retain in the final model. Such a recipe is shown below
accompanied by a call to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/expand_steps"><code>expand_steps()</code></a>
to construct a tuning grid. The grid parameter <code>num_comp</code> and
name <code>PCA</code> correspond to the argument and id of the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/step_pca"><code>step_pca()</code></a>
function to which the values <code>1:3</code> apply. The recipe and grid
may then be passed to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedInput"><code>TunedInput()</code></a>
for model fitting.</p>
<pre class="r"><code>## Preprocessing recipe with PCA steps
pca_rec &lt;- recipe(y ~ ., data = surv_train) %&gt;%
  role_case(stratum = y) %&gt;%
  step_center(all_predictors()) %&gt;%
  step_scale(all_predictors()) %&gt;%
  step_pca(all_predictors(), id = &quot;PCA&quot;)

## Tuning grid of number of PCA components
pca_grid &lt;- expand_steps(
  PCA = list(num_comp = 1:3)
)

## Tuning specification
tun_rec &lt;- TunedInput(pca_rec, grid = pca_grid)</code></pre>
<p>From the fit, the resulting model can be extracted with <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/as.MLModel"><code>as.MLModel()</code></a>.
The output shows that one principal component was selected. Resample
estimation of predictive performance is applied to a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedInput"><code>TunedInput</code></a>
specification for the selection. The default resampling method is
cross-validation. Other methods, performance metrics, and selection
statistics can be supplied to the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedInput"><code>TunedInput()</code></a>
arguments.</p>
<pre class="r"><code>## Input-tuned model fit and final trained model
model_fit &lt;- fit(tun_rec, model = GBMModel)
as.MLModel(model_fit)
#&gt; --- MLModel object -------------------------------------------------------------
#&gt; 
#&gt; Model name: GBMModel
#&gt; Label: Trained Generalized Boosted Regression
#&gt; Package: gbm
#&gt; Response types: factor, numeric, PoissonVariate, Surv
#&gt; Case weights support: TRUE
#&gt; Missing case removal: response
#&gt; Tuning grid: TRUE
#&gt; Variable importance: TRUE
#&gt; 
#&gt; Parameters:
#&gt; List of 5
#&gt;  $ n.trees          : num 100
#&gt;  $ interaction.depth: num 1
#&gt;  $ n.minobsinnode   : num 10
#&gt;  $ shrinkage        : num 0.1
#&gt;  $ bag.fraction     : num 0.5
#&gt; 
#&gt; === $TrainingStep1 =============================================================
#&gt; === TrainingStep object ===
#&gt; 
#&gt; Optimization method: Grid Search
#&gt; TunedModelRecipe log:
#&gt; # A tibble: 3 × 4
#&gt;   name          selected params$PCA$num_comp metrics$`C-Index`
#&gt;   &lt;chr&gt;         &lt;lgl&gt;                  &lt;int&gt;             &lt;dbl&gt;
#&gt; 1 ModelRecipe.1 TRUE                       1             0.740
#&gt; 2 ModelRecipe.2 FALSE                      2             0.720
#&gt; 3 ModelRecipe.3 FALSE                      3             0.725
#&gt; 
#&gt; Selected row: 1
#&gt; Metric: C-Index = 0.7399641</code></pre>
</div>
<div id="input-selection" class="section level3">
<h3>Input Selection</h3>
<p>Selection of recipes with different steps or predictors can be
conducted with <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedInput"><code>SelectedInput()</code></a>.</p>
<pre class="r"><code>## Preprocessing recipe without PCA steps
rec1 &lt;- recipe(y ~ sex + age + year + thickness + ulcer, data = surv_train) %&gt;%
  role_case(stratum = y)
rec2 &lt;- recipe(y ~ sex + age + year, data = surv_train) %&gt;%
  role_case(stratum = y)

## Selection among recipes with and without PCA steps
sel_rec &lt;- SelectedInput(
  rec1,
  rec2,
  TunedInput(pca_rec, grid = pca_grid)
)</code></pre>
<p>In this case, the third recipe with PCA steps is selected.</p>
<pre class="r"><code>## Input-selected model fit and model
model_fit &lt;- fit(sel_rec, model = GBMModel)
as.MLModel(model_fit)
#&gt; --- MLModel object -------------------------------------------------------------
#&gt; 
#&gt; Model name: GBMModel
#&gt; Label: Trained Generalized Boosted Regression
#&gt; Package: gbm
#&gt; Response types: factor, numeric, PoissonVariate, Surv
#&gt; Case weights support: TRUE
#&gt; Missing case removal: response
#&gt; Tuning grid: TRUE
#&gt; Variable importance: TRUE
#&gt; 
#&gt; Parameters:
#&gt; List of 5
#&gt;  $ n.trees          : num 100
#&gt;  $ interaction.depth: num 1
#&gt;  $ n.minobsinnode   : num 10
#&gt;  $ shrinkage        : num 0.1
#&gt;  $ bag.fraction     : num 0.5
#&gt; 
#&gt; === $TrainingStep1 =============================================================
#&gt; === TrainingStep object ===
#&gt; 
#&gt; Optimization method: Grid Search
#&gt; SelectedModelRecipe log:
#&gt; # A tibble: 3 × 4
#&gt;   name             selected params$id  metrics$`C-Index`
#&gt;   &lt;chr&gt;            &lt;lgl&gt;    &lt;chr&gt;                  &lt;dbl&gt;
#&gt; 1 ModelRecipe.1    FALSE    input.azpi             0.761
#&gt; 2 ModelRecipe.2    FALSE    input.aLHo             0.643
#&gt; 3 TunedModelRecipe TRUE     input.W4KN             0.796
#&gt; 
#&gt; Selected row: 3
#&gt; Metric: C-Index = 0.7960841
#&gt; 
#&gt; === $TrainingStep2 =============================================================
#&gt; === TrainingStep object ===
#&gt; 
#&gt; Optimization method: Grid Search
#&gt; TunedModelRecipe log:
#&gt; # A tibble: 3 × 4
#&gt;   name          selected params$PCA$num_comp metrics$`C-Index`
#&gt;   &lt;chr&gt;         &lt;lgl&gt;                  &lt;int&gt;             &lt;dbl&gt;
#&gt; 1 ModelRecipe.1 TRUE                       1             0.740
#&gt; 2 ModelRecipe.2 FALSE                      2             0.720
#&gt; 3 ModelRecipe.3 FALSE                      3             0.725
#&gt; 
#&gt; Selected row: 1
#&gt; Metric: C-Index = 0.7399641</code></pre>
<p>Selection can also be performed among traditional formulas, design
matrices, or model frames.</p>
<pre class="r"><code>## Traditional formulas
fo1 &lt;- y ~ sex + age + year + thickness + ulcer
fo2 &lt;- y ~ sex + age + year

## Selection among formulas
sel_fo &lt;- SelectedInput(fo1, fo2, data = surv_train)

## Input-selected model fit and final trained model
model_fit &lt;- fit(sel_fo, model = GBMModel)
as.MLModel(model_fit)</code></pre>
<p>In the previous examples, selection of different inputs was performed
with the same model (<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>).
Selection among different combinations of inputs and models is supported
with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelSpecification"><code>ModelSpecification()</code></a>
constructor.</p>
<pre class="r"><code>## Different combinations of inputs and models
sel_mfo &lt;- SelectedInput(
  ModelSpecification(fo1, data = surv_train, model = CoxModel),
  ModelSpecification(fo2, data = surv_train, model = GBMModel)
)

## Input-selected model fit and final trained model
model_fit &lt;- fit(sel_mfo)
as.MLModel(model_fit)</code></pre>
</div>
</div>
<div id="models" class="section level2">
<h2>Models</h2>
<p>Models define the functional relationships between predictor and
response variables from a given set of inputs.</p>
<div id="model-tuning" class="section level3">
<h3>Model Tuning</h3>
<p>Many of the package-supplied modeling functions have arguments, or
tuning parameters, that control aspects of their model fitting
algorithms. For example, <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>
parameters <code>n.trees</code> and <code>interaction.depth</code>
control the number of decision trees to fit and the maximum tree depths.
When called with a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedModel"><code>TunedModel</code></a>,
the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/fit"><code>fit()</code></a>
function performs model fitting over a grid of parameter values and
returns the model with the optimal values. Optimality is determined
based on the first performance metric of the <code>metrics</code>
argument to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedModel"><code>TunedModel()</code></a>
if given or the first default metric of the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/performance"><code>performance()</code></a>
function otherwise. Argument <code>grid</code> additionally controls the
construction of grid values and can be a single integer or vector of
integers whose positions or names match the parameters in a model’s
pre-defined tuning grid if one exists and which specify the number of
values used to construct the grid. Pre-defined <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedModel"><code>TunedModel</code></a>
grids can be extract and viewed apart from model fitting with <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/expand_modelgrid"><code>expand_modelgrid()</code></a>.
As shown in the output below, <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/as.MLModel"><code>as.MLModel()</code></a>
will extract a tuned model from fit results for viewing of the tuning
parameter grid values, the names of models fit to each, all calculated
metrics, the final model selected, the metric upon which its selection
was based, and its parameters.</p>
<pre class="r"><code>## Tune over automatic grid of model parameters
model_fit &lt;- fit(surv_fo, data = surv_train,
                 model = TunedModel(
                   GBMModel,
                   grid = 3,
                   control = surv_means_control,
                   metrics = c(&quot;CIndex&quot; = cindex, &quot;RMSE&quot; = rmse)
                 ))
(trained_model &lt;- as.MLModel(model_fit))
#&gt; --- MLModel object -------------------------------------------------------------
#&gt; 
#&gt; Model name: GBMModel
#&gt; Label: Trained Generalized Boosted Regression
#&gt; Package: gbm
#&gt; Response types: factor, numeric, PoissonVariate, Surv
#&gt; Case weights support: TRUE
#&gt; Missing case removal: response
#&gt; Tuning grid: TRUE
#&gt; Variable importance: TRUE
#&gt; 
#&gt; Parameters:
#&gt; List of 5
#&gt;  $ n.trees          : int 50
#&gt;  $ interaction.depth: int 1
#&gt;  $ n.minobsinnode   : num 10
#&gt;  $ shrinkage        : num 0.1
#&gt;  $ bag.fraction     : num 0.5
#&gt; 
#&gt; === $TrainingStep1 =============================================================
#&gt; === TrainingStep object ===
#&gt; 
#&gt; Optimization method: Grid Search
#&gt; TunedModel log:
#&gt; # A tibble: 9 × 4
#&gt;   name       selected params$n.trees $interaction.depth metrics$CIndex  $RMSE
#&gt;   &lt;chr&gt;      &lt;lgl&gt;             &lt;int&gt;              &lt;int&gt;          &lt;dbl&gt;  &lt;dbl&gt;
#&gt; 1 GBMModel.1 TRUE                 50                  1          0.765  3869.
#&gt; 2 GBMModel.2 FALSE                50                  2          0.750  5450.
#&gt; 3 GBMModel.3 FALSE                50                  3          0.739  7877.
#&gt; 4 GBMModel.4 FALSE               100                  1          0.746  3919.
#&gt; 5 GBMModel.5 FALSE               100                  2          0.730  5262.
#&gt; 6 GBMModel.6 FALSE               100                  3          0.720 10596.
#&gt; 7 GBMModel.7 FALSE               150                  1          0.726  4167.
#&gt; 8 GBMModel.8 FALSE               150                  2          0.712  5428.
#&gt; 9 GBMModel.9 FALSE               150                  3          0.699 16942.
#&gt; 
#&gt; Selected row: 1
#&gt; Metric: CIndex = 0.7647633</code></pre>
<p>Grid values may also be given as a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TuningGrid"><code>TuningGrid</code></a>
function, function name, or object; <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ParameterGrid"><code>ParameterGrid</code></a>
object; or data frame containing parameter values at which to evaluate
the model, such as that returned by <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/expand_params"><code>expand_params()</code></a>.</p>
<pre class="r"><code>## Tune over randomly sampled grid points
fit(surv_fo, data = surv_train,
    model = TunedModel(
      GBMModel,
      grid = TuningGrid(size = 100, random = 10),
      control = surv_means_control
    ))

## Tune over user-specified grid points
fit(surv_fo, data = surv_train,
    model = TunedModel(
      GBMModel,
      grid = expand_params(n.trees = c(25, 50, 100),
                           interaction.depth = 1:3),
      control = surv_means_control
    ))</code></pre>
<p>Statistics summarizing the resampled performance metrics across all
tuning parameter combinations can be obtained with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/summary"><code>summary()</code></a>
and <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/performance"><code>performance()</code></a>functions.</p>
<pre class="r"><code>summary(trained_model)
#&gt; --- $TrainingStep1 -------------------------------------------------------------
#&gt; # A tibble: 9 × 4
#&gt;   name       selected params$n.trees $interaction.depth metrics$CIndex  $RMSE
#&gt;   &lt;chr&gt;      &lt;lgl&gt;             &lt;int&gt;              &lt;int&gt;          &lt;dbl&gt;  &lt;dbl&gt;
#&gt; 1 GBMModel.1 TRUE                 50                  1          0.765  3869.
#&gt; 2 GBMModel.2 FALSE                50                  2          0.750  5450.
#&gt; 3 GBMModel.3 FALSE                50                  3          0.739  7877.
#&gt; 4 GBMModel.4 FALSE               100                  1          0.746  3919.
#&gt; 5 GBMModel.5 FALSE               100                  2          0.730  5262.
#&gt; 6 GBMModel.6 FALSE               100                  3          0.720 10596.
#&gt; 7 GBMModel.7 FALSE               150                  1          0.726  4167.
#&gt; 8 GBMModel.8 FALSE               150                  2          0.712  5428.
#&gt; 9 GBMModel.9 FALSE               150                  3          0.699 16942.

performance(trained_model) %&gt;% lapply(summary)
#&gt; $TrainingStep1
#&gt; , , Metric = CIndex
#&gt; 
#&gt;             Statistic
#&gt; Model             Mean    Median         SD       Min       Max NA
#&gt;   GBMModel.1 0.7647633 0.7630332 0.05151443 0.6497797 0.8632075  0
#&gt;   GBMModel.2 0.7502765 0.7549020 0.04636802 0.6688742 0.8349057  0
#&gt;   GBMModel.3 0.7388766 0.7500000 0.04594197 0.6621622 0.8197425  0
#&gt;   GBMModel.4 0.7463392 0.7601810 0.05087334 0.6497797 0.8160377  0
#&gt;   GBMModel.5 0.7301734 0.7345133 0.04361416 0.6621622 0.7847222  0
#&gt;   GBMModel.6 0.7199483 0.7122642 0.05168649 0.6216216 0.7889908  0
#&gt;   GBMModel.7 0.7263693 0.7385321 0.05069831 0.6351351 0.7896996  0
#&gt;   GBMModel.8 0.7121314 0.7169811 0.05331152 0.6199095 0.7847222  0
#&gt;   GBMModel.9 0.6994678 0.7156863 0.05314909 0.6081081 0.7639485  0
#&gt; 
#&gt; , , Metric = RMSE
#&gt; 
#&gt;             Statistic
#&gt; Model             Mean    Median        SD      Min       Max NA
#&gt;   GBMModel.1  3868.629  3321.249  1431.839 2123.875  7401.789  0
#&gt;   GBMModel.2  5450.093  4741.129  2438.173 2385.426 11695.273  0
#&gt;   GBMModel.3  7877.487  5827.739  5036.837 4192.463 20009.854  0
#&gt;   GBMModel.4  3919.126  3535.514  1454.999 2373.413  7558.280  0
#&gt;   GBMModel.5  5262.122  5052.969  1900.353 2280.193  8212.727  0
#&gt;   GBMModel.6 10595.888  8308.733  7057.327 4996.420 28610.367  0
#&gt;   GBMModel.7  4167.128  3789.596  1115.371 2587.440  6701.087  0
#&gt;   GBMModel.8  5427.518  6129.309  2313.742 2039.894  9212.369  0
#&gt;   GBMModel.9 16941.696 10865.160 16841.774 4914.743 71150.177  0</code></pre>
<p>Line plots of tuning results display the resampled metric means, or
another statistic specified with the <code>stat</code> argument, versus
the first tuning parameter values and with lines grouped according to
the remaining parameters, if any.</p>
<pre class="r"><code>plot(trained_model, type = &quot;line&quot;)
#&gt; $TrainStep1</code></pre>
<p><img src="img/using_strategies_tune_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="model-selection" class="section level3">
<h3>Model Selection</h3>
<p>Model selection can be conducted by calling <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/fit"><code>fit()</code></a>
with a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedModel"><code>SelectedModel</code></a>
to automatically choose from any combination of models and model
parameters. Selection has as a special case the just-discussed tuning of
a single model over a grid of parameter values. Combinations of model
functions, function names, or objects can be supplied to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedModel"><code>SelectedModel()</code></a>
in order to define sets of candidate models from which to select. An <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/expand_model"><code>expand_model()</code></a>
helper function is additionally available to expand a model over a grid
of tuning parameters for inclusion in the candidate set if so
desired.</p>
<pre class="r"><code>## Model interface for model selection
sel_model &lt;- SelectedModel(
  expand_model(GBMModel, n.trees = c(50, 100), interaction.depth = 1:2),
  GLMNetModel(lambda = 0.01),
  CoxModel,
  SurvRegModel
)

## Fit the selected model
fit(surv_fo, data = surv_train, model = sel_model)</code></pre>
<p>Selection may also be performed over candidate sets that include
tuned models. For instance, the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedModel"><code>SelectedModel()</code></a>
function is applicable to sets containing different classes of models
each individually tuned over a grid of parameters.</p>
<pre class="r"><code>## Model interface for selection among tuned models
sel_tun_model &lt;- SelectedModel(
  TunedModel(GBMModel, control = surv_means_control),
  TunedModel(GLMNetModel, control = surv_means_control),
  TunedModel(CoxModel, control = surv_means_control)
)

## Fit the selected tuned model
fit(surv_fo, data = surv_train, model = sel_tun_model)</code></pre>
</div>
</div>
<div id="ensemble-learning" class="section level2">
<h2>Ensemble Learning</h2>
<p>Ensemble learning models combine <span class="math inline">\(m = 1,
\ldots, M\)</span> base models as a strategy to improve predictive
performance. Two methods implemented in <strong>MachineShop</strong> are
<em>stacked regression</em> <span class="citation">(Breiman 1996)</span>
and <em>super learners</em> <span class="citation">(van der Laan,
Polley, and Hubbard 2007)</span>. Stacked regression fits a linear
combination of predictions from specified base learners to produce a
prediction function of the form <span class="math display">\[
\hat{f}(x) = \sum_{m=1}^M \hat{w}_m \hat{f}_m(x).
\]</span> Stacking weights <span class="math inline">\(w\)</span> are
estimated by (constrained) least squares regression of case responses
<span class="math inline">\(y_i\)</span> on predictions <span
class="math inline">\(\hat{f}_m^{-\kappa(i)}(x_i)\)</span> from learners
fit to data subsamples <span class="math inline">\(-\kappa(i)\)</span>
not containing the corresponding cases. In particular, they are obtained
as the solution <span class="math display">\[
\hat{w} = \underset{w}{\operatorname{argmin}} \sum_{i=1}^{N}\left(y_i -
\sum_{m=1}^{M} w_m \hat{f}_m^{-\kappa(i)}(x_i) \right)^2
\]</span> subject to the constraints that all <span
class="math inline">\(w_m \ge 0\)</span> and <span
class="math inline">\(\sum_m w_m = 1\)</span>. K-fold cross-validation
is the default subsampling method employed in the estimation, with the
other resampling methods provided by the package available as options.
Survival outcomes are handled with a modified version of the stacked
regression algorithm in which</p>
<ul>
<li>minimization of least squares is replaced by maximization of
Harrell’s concordance index <span class="citation">(1982)</span> to
accommodate censoring, and</li>
<li>prediction can only be performed on the same response type used for
the model fit; i.e., either survival means or survival probabilities at
given follow-up times.</li>
</ul>
<p>Super learners are a generalization of stacked regression that fit a
specified model, such as <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>,
to case responses <span class="math inline">\(y_i\)</span>, base learner
predictions <span
class="math inline">\(\hat{f}_m^{-\kappa(i)}(x_i)\)</span>, and
optionally also to the original predictor variables <span
class="math inline">\(x_i\)</span>. Given below are examples of a
stacked regression and super learner each fit with gradient boosted,
random forest, and Cox regression base learners. A separate gradient
boosted model is used as the super learner in the latter.</p>
<pre class="r"><code>## Stacked regression
stackedmodel &lt;- StackedModel(CoxModel, CForestModel, GLMBoostModel)
res_stacked &lt;- resample(surv_fo, data = surv_train, model = stackedmodel)
summary(res_stacked)
#&gt;          Statistic
#&gt; Metric         Mean   Median        SD       Min       Max NA
#&gt;   C-Index 0.7294869 0.762963 0.1275484 0.5194805 0.8556701  0

## Super learner
supermodel &lt;- SuperModel(CoxModel, CForestModel, GLMBoostModel,
                         model = GBMModel)
res_super &lt;- resample(surv_fo, data = surv_train, model = supermodel)
summary(res_super)
#&gt;          Statistic
#&gt; Metric         Mean    Median        SD       Min       Max NA
#&gt;   C-Index 0.7534803 0.8325472 0.1243104 0.5748899 0.8454545  0</code></pre>
</div>
<div id="methodology" class="section level2">
<h2>Methodology</h2>
<p>Combinations and multiple levels of nested meta-functions, inputs,
and models are possible. If model fitting involves a single
meta-function, performances of the inputs or models under consideration
are estimated with standard resampling, and the best performing model is
returned. Nestings of meta-functions are trained with nested resampling.
Consider the example below in which training involves input tuning and
model selection. In particular, a preprocessing recipe is tuned over the
number of predictor-derived principal components and model selection is
of an untuned <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>,
a tuned <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>,
and a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/StackedModel"><code>StackedModel</code></a>.</p>
<pre class="r"><code>## Preprocessing recipe with PCA steps
pca_rec &lt;- recipe(y ~ ., data = surv_train) %&gt;%
  role_case(stratum = y) %&gt;%
  step_center(all_predictors()) %&gt;%
  step_scale(all_predictors()) %&gt;%
  step_pca(all_predictors(), id = &quot;PCA&quot;)

## Tuning grid of number of PCA components
pca_grid &lt;- expand_steps(
  PCA = list(num_comp = 1:3)
)

## Input specification
tun_rec &lt;- TunedInput(pca_rec, grid = pca_grid)

## Model specification
sel_model &lt;- SelectedModel(
  GBMModel,
  TunedModel(GBMModel),
  StackedModel(CoxModel, TunedModel(CForestModel), TunedModel(GBMModel))
)

## Model fit and final trained model
model_fit &lt;- fit(tun_rec, model = sel_model)
as.MLModel(model_fit)</code></pre>
<p>Model fitting proceeds with instances of the specified model
selection nested within each of the input tuning grid parameter values.
Tuning of <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>
and construction of <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/StackedModel"><code>StackedModel</code></a>
are further nested within the model selection, with tuning of <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/CForestModel"><code>CForestModel</code></a>
and <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>
nested within <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/StackedModel"><code>StackedModel</code></a>.
Altogether, there are four levels of meta-input and meta-model functions
in the hierarchy.</p>
<p><img src="img/FigModelDAG.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Each meta-function is fit based on resample estimation (default:
cross-validation) of predictive performance. When one meta-function is
nested within another, nested resampling is employed, as illustrated in
the figure below.</p>
<p><img src="img/FigNestedCV.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Nesting of resampling routines is repeated recursively when a fit
involves multiple levels of nested meta-functions. For example,
predictive performance estimation for the training of <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedInput"><code>TunedInput(pca_rec, grid = pca_grid)</code></a>
involves up to three nested meta functions: <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedModel"><code>SelectedModel(...)</code></a>
→ <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/StackedModel"><code>StackedModel(...)</code></a>
→ <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedModel"><code>TunedModel(CForestModel)</code></a>.
For this relationship, an outer and three nested inner resampling loops
are executed as follows. First, <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/CForestModel"><code>CForestModel</code></a>
is tuned at the third inner resampling loop. Second, the tuned model is
passed to the second inner loop for construction of <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/StackedModel"><code>StackedModel</code></a>.
Third, the constructed model is passed to the first inner loop for model
selection from the candidate set. Finally, the selected model is passed
to the outer loop for tuning of the preprocessing recipe. Based on
resample performance estimation of the entire input/model specification,
one principal component is selected for the <code>GBMModel</code>.</p>
<pre class="r"><code>#&gt; === $TrainingStep1 =============================================================
#&gt; === TrainingStep object ===
#&gt; 
#&gt; Optimization method: Grid Search
#&gt; TunedModelRecipe log:
#&gt; # A tibble: 3 × 4
#&gt;   name          selected params$PCA$num_comp metrics$`C-Index`
#&gt;   &lt;chr&gt;         &lt;lgl&gt;                  &lt;int&gt;             &lt;dbl&gt;
#&gt; 1 ModelRecipe.1 TRUE                       1             0.741
#&gt; 2 ModelRecipe.2 FALSE                      2             0.730
#&gt; 3 ModelRecipe.3 FALSE                      3             0.702
#&gt; 
#&gt; Selected row: 1
#&gt; Metric: C-Index = 0.7405534</code></pre>
<p>In order to identify and return a final model fitted to the entire
input data, the hierarchy is traversed from top to bottom along the path
determined by the choice at each node. Steps along the path are labeled
<code>TrainStep1</code> and <code>TrainStep2</code> in the output. As
seen above in <code>TrainStep1</code>, one principal component is first
selected for the tuned input. Using an input recipe with one principal
component, the entire dataset is refit at <code>TrainStep2</code> to
finally select <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/GBMModel"><code>GBMModel</code></a>.</p>
<pre class="r"><code>#&gt; === $TrainingStep2 =============================================================
#&gt; === TrainingStep object ===
#&gt; 
#&gt; Optimization method: Grid Search
#&gt; SelectedModel log:
#&gt; # A tibble: 3 × 4
#&gt;   name         selected params$id  metrics$`C-Index`
#&gt;   &lt;chr&gt;        &lt;lgl&gt;    &lt;chr&gt;                  &lt;dbl&gt;
#&gt; 1 GBMModel     TRUE     model.1mQk             0.740
#&gt; 2 TunedModel   FALSE    model.hRF5             0.735
#&gt; 3 StackedModel FALSE    model.CYj0             0.653
#&gt; 
#&gt; Selected row: 1
#&gt; Metric: C-Index = 0.7399641</code></pre>
<p>After the series of training steps reaches the bottom of its
hierarchy, the final model is fitted to the entire dataset and
returned.</p>
<pre class="r"><code>#&gt; --- MLModel object -------------------------------------------------------------
#&gt; 
#&gt; Model name: GBMModel
#&gt; Label: Trained Generalized Boosted Regression
#&gt; Package: gbm
#&gt; Response types: factor, numeric, PoissonVariate, Surv
#&gt; Case weights support: TRUE
#&gt; Missing case removal: response
#&gt; Tuning grid: TRUE
#&gt; Variable importance: TRUE
#&gt; 
#&gt; Parameters:
#&gt; List of 5
#&gt;  $ n.trees          : num 100
#&gt;  $ interaction.depth: num 1
#&gt;  $ n.minobsinnode   : num 10
#&gt;  $ shrinkage        : num 0.1
#&gt;  $ bag.fraction     : num 0.5</code></pre>
<p>Generalization performance of the entire process can be estimated
with a call to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/resample"><code>resample()</code></a>.</p>
<pre class="r"><code>## Generalization performance of the modeling strategy
resample(tun_rec, model = sel_model)</code></pre>
<p>There is no conceptual limit to the number of nested inputs and
models that can be specified with the package. However, there are some
practical issues to consider.</p>
<dl>
<dt>Computational Expense</dt>
<dd>
Computational expense of nested resampling increases exponentially. For
instance, execution of <em>r</em> levels of a nested 10-fold
cross-validation algorithm is an O(10<sup><em>r</em></sup>) operation.
Runtimes can be decreased by registering multiple cores to run the
resampling algorithms in parallel. However, the exponential increase in
computational complexity quickly outpaces the number of available cores.
</dd>
<dt>Data Reduction</dt>
<dd>
Training data is reduced at each subsequent resampling level. For
10-fold cross-validation and a training set of <em>N</em> total cases,
there will be 0.9<sup><em>r</em></sup> cases available at each fold of
the <em>r</em><sup>th</sup> resampling algorithm. Bootstrapping could be
used, as an alternative to cross-validation, to ensure <em>N</em> cases
at each resampling level. However, the number of unique cases at level
<em>r</em> will be decreased to approximately
<em>N</em>(2/3)<sup><em>r</em></sup>.
</dd>
</dl>
</div>
</div>
<div id="modelspecification-class" class="section level1">
<h1>ModelSpecification Class</h1>
<p>The <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelSpecification"><code>ModelSpecification</code></a>
class allows response and predictor variables and a model that defines
the relationship between them to be packaged together into a single
container for ease of model fitting and assessment. The inputs and
models described previously can be included in a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelSpecification"><code>ModelSpecification</code></a>.
Resampling control and a method for optimizing tuning parameters are
also part of the specification. A <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelSpecification"><code>ModelSpecification</code></a>
object with its default or a user-specified control method has the
following characteristics.</p>
<ol style="list-style-type: decimal">
<li>Tuning of input and model objects is performed simultaneously over a
global grid of their parameter values.</li>
<li>The specification’s control method overrides those of any included
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedInput"><code>TunedInput</code></a>
or <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TunedModel"><code>TunedModel</code></a>.</li>
<li><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModeledInput"><code>ModeledInput</code></a>,
<a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedInput"><code>SelectedInput</code></a>,
and <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/SelectedModel"><code>SelectedModel</code></a>
objects are not allowed in the specification.</li>
</ol>
<p>The default tuning parameter optimization method is an exhaustive
grid search. Other methods can be employed with the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/set_optim"><code>set_optim</code></a>
functions.</p>
<table>
<colgroup>
<col width="31%" />
<col width="68%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Optimization Function</th>
<th align="left">Method</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/set_optim_bayes"><code>set_optim_bayes()</code></a></td>
<td align="left">Bayesian optimization with a Gaussian process model
<span class="citation">(Snoek, Larochelle, and Adams 2012)</span></td>
</tr>
<tr class="even">
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/set_optim_bfgs"><code>set_optim_bfgs()</code></a></td>
<td align="left">Limited-memory modification of quasi-Newton BFGS
optimization <span class="citation">(Byrd et al. 1995)</span></td>
</tr>
<tr class="odd">
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/set_optim_grid"><code>set_optim_grid()</code></a></td>
<td align="left">Exhaustive or random grid search</td>
</tr>
<tr class="even">
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/set_optim_method"><code>set_optim_method()</code></a></td>
<td align="left">User-defined optimization function</td>
</tr>
<tr class="odd">
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/set_optim_pso"><code>set_optim_pso()</code></a></td>
<td align="left">Particle swarm optimization <span
class="citation">(Bratton and Kennedy 2007)</span></td>
</tr>
<tr class="even">
<td align="left"><a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/set_optim_sann"><code>set_optim_sann()</code></a></td>
<td align="left">Simulated annealing <span class="citation">(Belisle
1992)</span></td>
</tr>
</tbody>
</table>
<pre class="r"><code>## Preprocessing recipe with PCA steps
pca_rec &lt;- recipe(y ~ ., data = surv_train) %&gt;%
  role_case(stratum = y) %&gt;%
  step_center(all_predictors()) %&gt;%
  step_scale(all_predictors()) %&gt;%
  step_pca(all_predictors(), id = &quot;PCA&quot;)

## Tuning grid of number of PCA components
pca_grid &lt;- expand_steps(
  PCA = list(num_comp = 1:3)
)

## Model specification
(modelspec &lt;- ModelSpecification(
  TunedInput(pca_rec, grid = pca_grid),
  TunedModel(GBMModel),
  control = surv_means_control
))
#&gt; --- ModelSpecification object ----------------------------------------------------------------------
#&gt; 
#&gt; === ModelRecipe object ===
#&gt; 
#&gt; ID: input.ICgC
#&gt; Outcome: y
#&gt; Predictors: sex, age, year, thickness, ulcer
#&gt; Untrained step IDs: step_center = center_AisIH, step_scale = scale_yD5ZK, step_pca = PCA
#&gt; Number of observations: 136
#&gt; 
#&gt; === MLModel object ===
#&gt; 
#&gt; Model name: GBMModel
#&gt; Label: Generalized Boosted Regression
#&gt; ID: model.ajOO
#&gt; 
#&gt; === Grid ===
#&gt; 
#&gt; # A tibble: 27 × 2
#&gt;    input.ICgC$PCA$num_comp model.ajOO$n.trees $interaction.depth
#&gt;                      &lt;int&gt;              &lt;int&gt;              &lt;int&gt;
#&gt;  1                       1                 50                  1
#&gt;  2                       1                 50                  2
#&gt;  3                       1                 50                  3
#&gt;  4                       1                100                  1
#&gt;  5                       1                100                  2
#&gt;  6                       1                100                  3
#&gt;  7                       1                150                  1
#&gt;  8                       1                150                  2
#&gt;  9                       1                150                  3
#&gt; 10                       2                 50                  1
#&gt; # … with 17 more rows
#&gt; 
#&gt; === TrainingParams object ===
#&gt; 
#&gt; ... GridSearch object
#&gt; Label: Grid Search
#&gt; 
#&gt; ... CVControl object
#&gt; Label: K-Fold Cross-Validation
#&gt; Folds: 5
#&gt; Repeats: 3

## Model fit with Bayesian optimization
bayes_fit &lt;- modelspec %&gt;% set_optim_bayes %&gt;% fit
as.MLModel(bayes_fit)
#&gt; --- MLModel object ---------------------------------------------------------------------------------
#&gt; 
#&gt; Model name: GBMModel
#&gt; Label: Trained Generalized Boosted Regression
#&gt; Package: gbm
#&gt; Response types: factor, numeric, PoissonVariate, Surv
#&gt; Case weights support: TRUE
#&gt; Missing case removal: response
#&gt; Tuning grid: TRUE
#&gt; Variable importance: TRUE
#&gt; 
#&gt; Parameters:
#&gt; List of 5
#&gt;  $ n.trees          : num 150
#&gt;  $ interaction.depth: num 3
#&gt;  $ n.minobsinnode   : num 10
#&gt;  $ shrinkage        : num 0.1
#&gt;  $ bag.fraction     : num 0.5
#&gt; 
#&gt; === $TrainingStep1 =================================================================================
#&gt; === TrainingStep object ===
#&gt; 
#&gt; Optimization method: Bayesian Optimization
#&gt; ModelSpecification log:
#&gt; # A tibble: 12 × 5
#&gt;    name         epoch selected params$input.ICgC$PCA$num_comp $model.a…¹ metri…²
#&gt;    &lt;chr&gt;        &lt;int&gt; &lt;lgl&gt;                             &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;
#&gt;  1 ModelSpec.1      0 FALSE                                 2        108   0.721
#&gt;  2 ModelSpec.2      0 FALSE                                 1        117   0.728
#&gt;  3 ModelSpec.3      0 FALSE                                 3         70   0.742
#&gt;  4 ModelSpec.4      0 FALSE                                 3        138   0.742
#&gt;  5 ModelSpec.5      0 FALSE                                 2         80   0.721
#&gt;  6 ModelSpec.6      1 FALSE                                 3        107   0.743
#&gt;  7 ModelSpec.7      2 FALSE                                 3        108   0.741
#&gt;  8 ModelSpec.8      3 FALSE                                 3         89   0.742
#&gt;  9 ModelSpec.9      4 FALSE                                 3        100   0.742
#&gt; 10 ModelSpec.10     5 FALSE                                 3         80   0.743
#&gt; # … with 2 more rows, 1 more variable:
#&gt; #   params$model.ajOO$interaction.depth &lt;dbl&gt;, and abbreviated variable names
#&gt; #   ¹​$model.ajOO$n.trees, ²​metrics$`C-Index`
#&gt; 
#&gt; Selected row: 12
#&gt; Metric: C-Index = 0.751118</code></pre>
<p>Alternatively, a value of <code>NULL</code> may be specified as the
control method in a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelSpecifiction"><code>ModelSpecifiction</code></a>
so that any package input or model object is allowed, object-specific
control structures and training parameters are used for selection and
tuning, and objects are trained sequentially with nested resampling
rather than simultaneously with a global grid. This, in essence, is how
input and model objects are handled if passed separately in to the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/fit"><code>fit()</code></a>
and <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/resample"><code>resample()</code></a>
functions apart from a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelSpecification"><code>ModelSpecification</code></a>.
Having them together in a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelSpecifiction"><code>ModelSpecifiction</code></a>
has the advantage of simplifying the function calls to be in terms of
one object instead of two.</p>
<pre class="r"><code>ModelSpecification(
  TunedInput(pca_rec, grid = pca_grid),
  TunedModel(GBMModel),
  control = NULL
)
#&gt; --- ModelSpecification object ----------------------------------------------------------------------
#&gt; 
#&gt; === TunedModelRecipe object ===
#&gt; 
#&gt; Outcome: y
#&gt; Predictors: sex, age, year, thickness, ulcer
#&gt; Untrained steps: step_center, step_scale, step_pca
#&gt; Number of observations: 136
#&gt; 
#&gt; === TunedModel object ===
#&gt; 
#&gt; Model name: TunedModel
#&gt; Label: Grid Tuned GBMModel
#&gt; 
#&gt; ... MLModel object
#&gt; Model name: GBMModel
#&gt; Label: Generalized Boosted Regression</code></pre>
</div>
<div id="global-settings" class="section level1">
<h1>Global Settings</h1>
<p>Core default behaviors of functions in the package can be viewed or
changed globally through the <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/settings"><code>settings()</code></a>
function. The function accepts one or more character names of settings
to view, <code>name = value</code> pairs giving the values of settings
to change, or a vector of these, with available settings summarized
below.</p>
<dl>
<dt><code>control</code></dt>
<dd>
function, function name, or object defining a default resampling method
[default: <code>"CVControl"</code>].
</dd>
<dt><code>cutoff</code></dt>
<dd>
numeric (0, 1) threshold above which binary factor probabilities are
classified as events and below which survival probabilities are
classified [default: 0.5].
</dd>
<dt><code>distr.SurvMeans</code></dt>
<dd>
character string specifying distributional approximations to estimated
survival curves for predicting survival means. Choices are
<code>"empirical"</code> for the Kaplan-Meier estimator,
<code>"exponential"</code>, <code>"rayleigh"</code>, or
<code>"weibull"</code> (default).
</dd>
<dt><code>distr.SurvProbs</code></dt>
<dd>
character string specifying distributional approximations to estimated
survival curves for predicting survival events/probabilities. Choices
are <code>"empirical"</code> (default) for the Kaplan-Meier estimator,
<code>"exponential"</code>, <code>"rayleigh"</code>, or
<code>"weibull"</code>.
</dd>
<dt><code>grid</code></dt>
<dd>
<code>size</code> argument to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TuningGrid"><code>TuningGrid()</code></a>
indicating the number of parameter-specific values to generate
automatically for tuning of models that have pre-defined grids or a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/TuningGrid"><code>TuningGrid()</code></a>
function, function name, or object [default: 3].
</dd>
<dt><code>method.EmpiricalSurv</code></dt>
<dd>
character string specifying the empirical method of estimating baseline
survival curves for Cox proportional hazards-based models. Choices are
<code>"breslow"</code> or <code>"efron"</code> (default).
</dd>
<dt><code>metrics.ConfusionMatrix</code></dt>
<dd>
function, function name, or vector of these with which to calculate
performance metrics for confusion matrices [default:
<code>c(Accuracy = "accuracy", Kappa = "kappa2", `Weighted Kappa` = "weighted_kappa2", Sensitivity = "sensitivity", Specificity = "specificity")</code>].
</dd>
<dt><code>metrics.factor</code></dt>
<dd>
function, function name, or vector of these with which to calculate
performance metrics for factor responses [default:
<code>c(Brier = "brier", Accuracy = "accuracy", Kappa = "kappa2", `Weighted Kappa` = "weighted_kappa2", `ROC AUC` = "roc_auc", Sensitivity = "sensitivity", Specificity = "specificity")</code>].
</dd>
<dt><code>metrics.matrix</code></dt>
<dd>
function, function name, or vector of these with which to calculate
performance metrics for matrix responses [default:
<code>c(RMSE = "rmse", R2 = "r2", MAE = "mae")</code>].
</dd>
<dt><code>metrics.numeric</code></dt>
<dd>
function, function name, or vector of these with which to calculate
performance metrics for numeric responses [default:
<code>c(RMSE = "rmse", R2 = "r2", MAE = "mae")</code>].
</dd>
<dt><code>metrics.Surv</code></dt>
<dd>
function, function name, or vector of these with which to calculate
performance metrics for survival responses [default:
<code>c(`C-Index` = "cindex", Brier = "brier", `ROC AUC` = "roc_auc", Accuracy = "accuracy")</code>].
</dd>
<dt><code>print_max</code></dt>
<dd>
number of models or data rows to show with print methods or
<code>Inf</code> to show all [default: 10].
</dd>
<dt><code>require</code></dt>
<dd>
names of installed packages to load during parallel execution of
resampling algorithms [default: <code>"MachineShop"</code>].
</dd>
<dt><code>reset</code></dt>
<dd>
character names of settings to reset to their default values.
</dd>
<dt><code>RHS.formula</code></dt>
<dd>
non-modifiable character vector of operators and functions allowed in
traditional formula specifications.
</dd>
<dt><code>stat.Curve</code></dt>
<dd>
function or character string naming a function to compute one summary
statistic at each cutoff value of resampled metrics in performance
curves, or <code>NULL</code> for resample-specific metrics [default:
<code>"base::mean"</code>].
</dd>
<dt><code>stat.Resample</code></dt>
<dd>
function or character string naming a function to compute one summary
statistic to control the ordering of models in plots [default:
<code>"base::mean"</code>].
</dd>
<dt><code>stat.TrainingParams</code></dt>
<dd>
function or character string naming a function to compute one summary
statistic on resampled performance metrics for input selection or tuning
or for model selection or tuning [default: <code>"base::mean"</code>].
</dd>
<dt><code>stats.PartialDependence</code></dt>
<dd>
function, function name, or vector of these with which to compute
partial dependence summary statistics [default:
<code>c(Mean = "base::mean")</code>].
</dd>
<dt><code>stats.Resample</code></dt>
<dd>
function, function name, or vector of these with which to compute
summary statistics on resampled performance metrics [default:
<code>c(Mean = "base::mean", Median = "stats::median", SD = "stats::sd", Min = "base::min", Max = "base::max")</code>].
</dd>
</dl>
<p>A call to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/settings"><code>settings()</code></a>
with <code>"reset"</code> will restore all package defaults and with no
arguments will display the current values of all. Settings may also be
supplied as a single unnamed argument which is a named list. Partial
matching of setting names is supported. The setting value is returned if
only one is specified to view. Otherwise, a list is returned with the
values of specified settings as they existed prior to any requested
changes. Such a list can be passed as an argument to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/settings"><code>settings()</code></a>
to restore their values.</p>
<pre class="r"><code>## Change settings
presets &lt;- settings(control = &quot;BootControl&quot;, grid = 10)

## View one setting
settings(&quot;control&quot;)
#&gt; [1] &quot;BootControl&quot;

## View multiple settings
settings(&quot;control&quot;, &quot;grid&quot;)
#&gt; $control
#&gt; [1] &quot;BootControl&quot;
#&gt; 
#&gt; $grid
#&gt; --- TuningGrid object ------------------------------------------------------------------------------
#&gt; 
#&gt; Grid size: 10
#&gt; Random samples: FALSE

## Restore the previous settings
settings(presets)</code></pre>
</div>
<div id="package-extensions" class="section level1">
<h1>Package Extensions</h1>
<p>Custom models and metrics can be defined with <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLModel"><code>MLModel()</code></a>
and <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLMetric"><code>MLMetric()</code></a>
for use with the model fitting, prediction, and performance assessment
tools provided by the package.</p>
<div id="custom-models" class="section level2">
<h2>Custom Models</h2>
<p>The <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLModel"><code>MLModel()</code></a>
function creates a model object that can be used with the previously
described fitting functions. It take the following arguments.</p>
<dl>
<dt><code>name</code></dt>
<dd>
character name of the object to which the model is assigned.
</dd>
<dt><code>label</code></dt>
<dd>
optional character descriptor for the model (default:
<code>name</code>).
</dd>
<dt><code>packages</code></dt>
<dd>
character vector of packages upon which the model depends. Each name may
be optionally followed by a comment in parentheses specifying a version
requirement. The comment should contain a comparison operator,
whitespace and a valid version number,
e.g. <code>"xgboost (&gt;= 1.3.0)"</code>.
</dd>
<dt><code>response_types</code></dt>
<dd>
character vector of response variable types to which the model can be
fit. Supported types are <code>"binary"</code>,
<code>"BinomialVariate"</code>, <code>"DiscreteVariate"</code>,
<code>"factor"</code>, <code>"matrix"</code>,
<code>"NegBinomialVariate"</code>, <code>"numeric"</code>,
<code>"ordered"</code>, <code>"PoissonVariate"</code>, and
<code>"Surv"</code>.
</dd>
<dt><code>fit</code></dt>
<dd>
model fitting function whose arguments are a <code>formula</code>, a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelFrame"><code>ModelFrame</code></a>
named <code>data</code>, case <code>weights</code>, and an ellipsis.
Argument <code>data</code> may be converted to a data frame with the
<code>as.data.frame()</code> function as is commonly needed. The fit
function should return the object resulting from the model fit.
</dd>
<dt><code>predict</code></dt>
<dd>
prediction function whose arguments are the <code>object</code> returned
by <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/fit"><code>fit()</code></a>,
a <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/ModelFrame"><code>ModelFrame</code></a>
named <code>newdata</code> of predictor variables, optional vector of
<code>times</code> at which to predict survival, and an ellipsis.
Argument <code>data</code> may be converted to a data frame with the
<code>as.data.frame()</code> function as needed. Values returned by the
function should be formatted according to the response variable types
below.
</dd>
</dl>
<ul>
<li><code>factor</code> : matrix whose columns contain the probabilities
for multi-level factors or vector of probabilities for the second level
of binary factors.</li>
<li><code>matrix</code> : matrix of predicted responses.</li>
<li><code>numeric</code> : vector or column matrix of predicted
responses.</li>
<li><code>Surv</code> : matrix whose columns contain survival
probabilities at <code>times</code> if supplied or vector of predicted
survival means otherwise.</li>
</ul>
<dl>
<dt><code>varimp</code></dt>
<dd>
variable importance function whose arguments are the <code>object</code>
returned by <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/fit"><code>fit()</code></a>,
optional arguments passed from calls to <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/varimp"><code>varimp()</code></a>,
and an ellipsis. The function should return a vector of importance
values named after the predictor variables or a matrix or data frame
whose rows are named after the predictors.
</dd>
</dl>
<pre class="r"><code>## Logistic regression model extension
LogisticModel &lt;- MLModel(
  name = &quot;LogisticModel&quot;,
  label = &quot;Logistic Model&quot;,
  response_types = &quot;binary&quot;,
  weights = TRUE,
  fit = function(formula, data, weights, ...) {
    glm(formula, data = as.data.frame(data), weights = weights,
        family = binomial, ...)
  },
  predict = function(object, newdata, ...) {
    predict(object, newdata = as.data.frame(newdata), type = &quot;response&quot;)
  },
  varimp = function(object, ...) {
    pchisq(coef(object)^2 / diag(vcov(object)), 1)
  }
)</code></pre>
</div>
<div id="custom-metrics" class="section level2">
<h2>Custom Metrics</h2>
<p>The <a
href="https://www.rdocumentation.org/packages/MachineShop/versions/3.6.0/topics/MLMetric"><code>MLMetric()</code></a>
function creates a metric object that can be used as previously
described for the model performance metrics. Its first argument is a
function to compute the metric, defined to accept <code>observed</code>
and <code>predicted</code> as the first two arguments and with an
ellipsis to accommodate others. Its remaining arguments are as
follows.</p>
<dl>
<dt><code>name</code></dt>
<dd>
character name of the object to which the metric is assigned.
</dd>
<dt><code>label</code></dt>
<dd>
optional character descriptor for the metric (default:
<code>name</code>).
</dd>
<dt><code>maximize</code></dt>
<dd>
logical indicating whether higher values of the metric correspond to
better predictive performance.
</dd>
</dl>
<pre class="r"><code>## F2 score metric extension
f2_score &lt;- MLMetric(
  function(observed, predicted, ...) {
    f_score(observed, predicted, beta = 2, ...)
  },
  name = &quot;f2_score&quot;,
  label = &quot;F2 Score&quot;,
  maximize = TRUE
)</code></pre>
</div>
<div id="usage" class="section level2">
<h2>Usage</h2>
<p>Once created, model and metric extensions can be used with the
package-supplied fitting and performance functions.</p>
<pre class="r"><code>## Logistic regression analysis
data(Pima.tr, package = &quot;MASS&quot;)
res &lt;- resample(type ~ ., data = Pima.tr, model = LogisticModel)
summary(performance(res, metric = f2_score))
#&gt;           Statistic
#&gt; Metric          Mean    Median         SD       Min       Max NA
#&gt;   f2_score 0.5499676 0.5714286 0.05093445 0.4761905 0.6060606  0</code></pre>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-andersen:1993:SMB" class="csl-entry">
Andersen, Per K, Ornulf Borgan, Richard D Gill, and Niels Keiding. 1993.
<em>Statistical Models Based on Counting Processes</em>. New York:
Springer.
</div>
<div id="ref-belisle:1992:CTC" class="csl-entry">
Belisle, Claude J. P. 1992. <span>“Convergence Theorems for a Class of
Simulated Annealing Algorithms on Rd.”</span> <em>Journal of Applied
Probability</em> 29: 885–95.
</div>
<div id="ref-bouckaert:2004:ERS" class="csl-entry">
Bouckaert, Remco R, and Eibe Frank. 2004. <span>“Evaluating the
Replicability of Significance Tests for Comparing Learning
Algorithms.”</span> In <em>Advances in Knowledge Discovery and Data
Mining</em>, 3–12. Berlin, Heidelberg: Springer.
</div>
<div id="ref-bratton:2007:DSP" class="csl-entry">
Bratton, Daniel, and James Kennedy. 2007. <span>“Defining a Standard for
Particle Swarm Optimization.”</span> In <em>2007 IEEE Swarm Intelligence
Symposium</em>, 120–27. <a
href="https://doi.org/10.1109/SIS.2007.368035">https://doi.org/10.1109/SIS.2007.368035</a>.
</div>
<div id="ref-breiman:1996:SR" class="csl-entry">
Breiman, Leo. 1996. <span>“Stacked Regression.”</span> <em>Machine
Learning</em> 24: 49–64.
</div>
<div id="ref-breslow:1972:DPC" class="csl-entry">
Breslow, Norman E. 1972. <span>“Discussion of <span
class="nocase">Professor Cox’s</span> Paper.”</span> <em>Journal of the
Royal Statistical Society, Series B</em> 34: 216–17.
</div>
<div id="ref-byrd:1994:LMA" class="csl-entry">
Byrd, Richard H., Peihuang Lu, Jorge Nocedal, and Ciyou Zhu. 1995.
<span>“A Limited Memory Algorithm for Bound Constrained
Optimization.”</span> <em>SIAM Journal on Scientific Computing</em> 16
(5): 1190–1208. <a
href="https://doi.org/10.1137/0916069">https://doi.org/10.1137/0916069</a>.
</div>
<div id="ref-davis:2006:RPR" class="csl-entry">
Davis, Jesse, and Mark Goadrich. 2006. <span>“The Relationship Between
Precision-Recall and <span>ROC</span> Curves.”</span> In <em>Proceedings
of the 23rd International Conference on Machine Learning</em>, 233–40.
ICML ’06. New York, NY, USA: ACM.
</div>
<div id="ref-davison:1997:BMA" class="csl-entry">
Davison, Anthony C, and David V Hinkley. 1997. <em>Bootstrap Methods and
Their Application</em>. New York, NY, USA: Cambridge University Press.
</div>
<div id="ref-efron:1967:PFB" class="csl-entry">
Efron, Bradley. 1967. <span>“The Two Sample Problem with Censored
Data.”</span> In <em>Proceedings of the Fifth Berkeley Symposium on
Mathematical Statistics and Probability, Volume 4: Biology and Problems
of Health</em>, 831–53. Berkeley, California: University of California
Press.
</div>
<div id="ref-efron:1977:ECL" class="csl-entry">
———. 1977. <span>“The Efficiency of <span class="nocase">Cox’s</span>
Likelihood Function for Censored Data.”</span> <em>Journal of the
American Statistical Association</em> 72 (359): 557–65.
</div>
<div id="ref-efron:1986:HBA" class="csl-entry">
———. 1986. <span>“How Biased Is the Apparent Error Rate of a Prediction
Rule?”</span> <em>Journal of the American Statistical Association</em>
81 (394): 461–70.
</div>
<div id="ref-efron:1983:LLB" class="csl-entry">
Efron, Bradley, and Gail Gong. 1983. <span>“A Leisurely Look at the
Bootstrap, the Jackknife, and Cross-Validation.”</span> <em>The American
Statistician</em> 37 (1): 36–48.
</div>
<div id="ref-efron:1993:IB" class="csl-entry">
Efron, Bradley, and Robert J Tibshirani. 1993. <em>An Introduction to
the Bootstrap</em>. Monographs on Statistics and Applied Probability 57.
Boca Raton, Florida, USA: Chapman &amp; Hall/CRC.
</div>
<div id="ref-fawcett:2006:IRA" class="csl-entry">
Fawcett, Tom. 2006. <span>“An Introduction to <span>ROC</span>
Analysis.”</span> <em>Pattern Recognition Letters</em> 27 (8): 861–74.
</div>
<div id="ref-fisher:2019:AMW" class="csl-entry">
Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. 2019.
<span>“Models Are Wrong, but Many Are Useful: Learning a Variable’s
Importance by Studying an Entire Class of Prediction Models
Simultaneously.”</span> <em>Machine Learning Research</em> 20: 1–81.
</div>
<div id="ref-graf:1999:ACP" class="csl-entry">
Graf, Erika, Claudia Schmoor, Willi Sauerbrei, and Martin Schumacher.
1999. <span>“Assessment and Comparison of Prognostic Classification
Schemes for Survival Data.”</span> <em>Statistics in Medicine</em> 18
(17–18): 2529–45.
</div>
<div id="ref-greenwell:2019:GBM" class="csl-entry">
Greenwell, Brandon, Bradley Boehmke, Jay Cunningham, and GBM Developers.
2019. <em><span class="nocase">gbm</span>: Generalized Boosted
Regression Models</em>. <a
href="https://CRAN.R-project.org/package=gbm">https://CRAN.R-project.org/package=gbm</a>.
</div>
<div id="ref-harrell:1982:EYM" class="csl-entry">
Harrell, Frank E, Robert M Califf, David B Pryor, Kerry L Lee, and
Robert A Rosati. 1982. <span>“Evaluating the Yield of Medical
Tests.”</span> <em>JAMA</em> 247 (18): 2543–46.
</div>
<div id="ref-harrell:1996:MPM" class="csl-entry">
Harrell, Frank E, Kerry L Lee, and Daniel B Mark. 1996.
<span>“Multivariable Prognostic Models: Issues in Developing Models,
Evaluating Assumptions and Adequacy, and Measuring and Reducing
Errors.”</span> <em>Statistics in Medicine</em> 15 (4): 361–87.
</div>
<div id="ref-hastie:2009:ESL7" class="csl-entry">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <span>“The
Elements of Statistical Learning: Data Mining, Inference, and
Prediction, Second Edition.”</span> In. Springer Series in Statistics.
New York, NY, USA: Springer.
</div>
<div id="ref-heagerty:2004:TDR" class="csl-entry">
Heagerty, Patrick J, Thomas Lumley, and Margaret S Pepe. 2004.
<span>“Time-Dependent <span>ROC</span> Curves for Censored Survival Data
and a Diagnostic Marker.”</span> <em>Biometrics</em> 56 (2): 337–44.
</div>
<div id="ref-kohavi:1995:SCB" class="csl-entry">
Kohavi, Ron. 1995. <span>“A Study of Cross-Validation and Bootstrap for
Accuracy Estimation and Model Selection.”</span> In <em>Proceedings of
the 14th International Joint Conference on Artificial Intelligence -
Volume 2</em>, 1137–43. IJCAI’95. San Francisco, CA, USA: Morgan
Kaufmann Publishers Inc.
</div>
<div id="ref-kuhn:2020:RPT" class="csl-entry">
Kuhn, Max, and Hadley Wickham. 2020. <em><span
class="nocase">recipes</span>: Preprocessing Tools to Create Design
Matrices</em>. <a
href="https://CRAN.R-project.org/package=recipes">https://CRAN.R-project.org/package=recipes</a>.
</div>
<div id="ref-microsoft:2019:DFS" class="csl-entry">
Microsoft Corporation, and Stephen Weston. 2019a. <em><span
class="nocase">doSNOW</span>: Foreach Parallel Adaptor for the ’Snow’
Package</em>. <a
href="https://CRAN.R-project.org/package=doSNOW">https://CRAN.R-project.org/package=doSNOW</a>.
</div>
<div id="ref-microsoft:2019:DFP" class="csl-entry">
Microsoft Corporation, and Steve Weston. 2019b. <em><span
class="nocase">doParallel</span>: Foreach Parallel Adaptor for the
’Parallel’ Package</em>. <a
href="https://CRAN.R-project.org/package=doParallel">https://CRAN.R-project.org/package=doParallel</a>.
</div>
<div id="ref-microsoft:2019:FPF" class="csl-entry">
Microsoft, and Steve Weston. 2019. <em><span
class="nocase">foreach</span>: Provides Foreach Looping Construct for
r</em>. <a
href="https://CRAN.R-project.org/package=foreach">https://CRAN.R-project.org/package=foreach</a>.
</div>
<div id="ref-nadeau:2003:IGE" class="csl-entry">
Nadeau, Claude, and Yoshua Bengio. 2003. <span>“Inference for the
Generalization Error.”</span> <em>Machine Learning</em> 52: 239–81.
</div>
<div id="ref-perkins:2006:IOC" class="csl-entry">
Perkins, Neil J, and Enrique F Schisterman. 2006. <span>“The
Inconsistency of "Optimal" Cutpoints Obtained Using Two Criteria Based
on the Receiver Operating Characteristic Curve.”</span> <em>American
Journal of Epidemiology</em> 163 (7): 670–75.
</div>
<div id="ref-snoek:2012:PBO" class="csl-entry">
Snoek, Jasper, Hugo Larochelle, and Ryan P. Adams. 2012.
<span>“Practical <span>B</span>ayesian Optimization of Machine Learning
Algorithms.”</span> <a
href="https://arxiv.org/abs/1206.2944">https://arxiv.org/abs/1206.2944</a>.
</div>
<div id="ref-therneau:2020:SA" class="csl-entry">
Therneau, Terry M. 2020. <em>A Package for Survival Analysis in r</em>.
<a
href="https://CRAN.R-project.org/package=survival">https://CRAN.R-project.org/package=survival</a>.
</div>
<div id="ref-vanderLaan:2007:SL" class="csl-entry">
van der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007.
<span>“Super Learner.”</span> <em>Statistical Applications in Genetics
and Molecular Biology</em> 6 (1).
</div>
<div id="ref-wickham:2016:GEG" class="csl-entry">
Wickham, Hadley. 2016. <em><span class="nocase">ggplot2</span>: Elegant
Graphics for Data Analysis</em>. Springer-Verlag New York. <a
href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</div>
<div id="ref-youden:1950:IRD" class="csl-entry">
Youden, William J. 1950. <span>“Index for Rating Diagnostic
Tests.”</span> <em>Cancer</em> 3 (1): 32–35.
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
